[{"content":"今年我有幸参加了开源之夏 (Summer OSPP) 活动，并成功中选了 面向 openEuler distroless 镜像的 SDF 自动生成工具开发 项目。\n就在几天前，我收到了 Gitee 的合并通知。那一刻，我感觉自己几个月来的努力都有了最好的回报。经过一段时间的开发、学习和与华为老师的深入交流，我提交的 两 四个 PR 终于先后被合并了！这不仅仅是代码的合入，对我而言意义重大，毕竟这不再是个人玩具项目，而是为华为 openEuler 生态的基础软件贡献代码。我想借此机会，分享一下这段令人兴奋的旅程。\n开源之夏 是中国科学院软件研究所发起的“开源软件供应链点亮计划”系列活动，由中国科学院软件研究所与华为共同主办、中科南京软件技术研究院承办。开源之夏为学生提供了接触和贡献高质量开源项目的机会，通过真实的开源项目实践，培养和发掘优秀的开发者，促进优秀开源软件社区的蓬勃发展，助力开源软件供应链建设。开源之夏于 2020 年正式发起，今年已经是第六届，该活动已成为国内开源社区中极具影响力的人才培养平台。 2025 年的开源之夏联合了全球 182 个开源社区，共发布了 566 个项目任务，覆盖了操作系统、人工智能、数据库、云原生、RISC-V 等多个前沿技术领域，吸引了全球 450 所高校，两千多名学生的报名，提交了项目申请书 1176 份，最终 518 名学生中选。\n我的任务：为 splitter 打造 SDF 自动生成器 首先简单介绍一下我参与的项目 splitter。\n在容器化的世界里，我们追求更小、更安全的镜像。openEuler 的 Distroless 镜像就是为此而生。它的核心思想是，不再完整地打包一个 RPM 软件包，而是将其精细地“切分”成多个功能独立的“Slice”，软件包之间的依赖关系也就更精细地表现为 slice 之间的依赖。然后我们以 slice 为最小构建单元生成最终的 distroless 镜像，可以有效减少冗余文件，进而降低安全风险。\n如上图所示，软件包 B 依赖于软件包 A 等价于 B_slice1 和 B_slice2 依赖于 A_slice1、A_slice2，在生成 B 的应用镜像时，可以不再打包 A_slice3 所包含的文件。\nsplitter 通过解析 RPM 软件包，并根据预定义的规则文件 SDF (Slice Definition File)，将软件包切分成多个 slice。\nSDF (Slice Definition File) 精准定义每个软件包的拆分规则。目前，所有的 SDF 文件都由社区专家手工编写，存放在 slice-releases 仓库中。当软件包数量和版本不断增多时，手工编写 SDF 就成了一个巨大的瓶颈。\n我的任务，就是为splitter开发一个gen命令，实现 SDF 文件的自动化生成。\nSDF 生成器的核心实现 我的任务是自动化生成 SDF 文件，但在开始之前，我们首先要理解：SDF 文件究竟是什么？\nSDF 文件的构成 一个 SDF（Slice Definition File）文件，本质上是一个 YAML 格式的“软件包拆分说明书”。它精确地定义了一个 RPM 包如何被拆解成多个功能独立的、可按需组合的“Slice”。一个典型的 SDF（以brotli.yaml为例）包含两个核心部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package: brotli deps: - brotli_copyright slices: libs: deps: - glibc_libs contents: common: - /usr/lib64/libbrotlicommon.so.1* - /usr/lib64/libbrotlidec.so.1* - /usr/lib64/libbrotlienc.so.1* copyright: contents: common: - /usr/share/licenses/brotli/LICENSE slices (切片)：这是主体部分，定义了包内每个文件的归属。 contents: 列出了这个 Slice 包含的所有文件路径。比如，brotli_libs slice 包含了所有的.so库文件。 deps (依赖)：定义了 Slice 之间的依赖关系。 deps: 列出了要让当前 Slice 正常工作，需要依赖哪些其他的 Slice。比如，brotli_libs slice 依赖于glibc_libs，因为brotli的库函数调用了glibc的底层功能。 SDF 的自动化生成流程 理解了 SDF 的构成后，我设计了一套自动化的流水线来生成它。整个流程就像一个工厂的生产线，每一步都有明确的输入和输出：\n下载 (Download): 首先，从 openEuler 的仓库中下载指定的目标 RPM 包。 解压 (Extract): 将 RPM 包解压到一个临时目录，暴露出其内部的所有文件。 文件分类 (Classify Files): 遍历所有文件，根据一系列规则，将它们分配到不同的 Slice 中。这是填充 SDF 中slices和contents部分的核心步骤。 依赖分析 (Analyze Dependencies): 对分类好的 Slice（特别是包含二进制文件和库的）进行分析，找出它们之间的依赖关系。这是填充 SDF 中deps部分的核心步骤。 生成 SDF (Generate): 最后，将分类和依赖分析的结果，按照 SDF 的 YAML 格式，写入到最终的文件中。 在这条流水线中，最核心、最具技术挑战性的，无疑是“文件分类”和“依赖分析”这两个环节。\n文件分类原理 文件分类就是确定 RPM 包里的每一个文件，应该属于哪个 Slice。\n一个软件包通常包含可执行文件、库文件、配置文件、版权声明等。我实现了一个基于规则的智能分类器，它的工作思路是：\n建立规则：我分析了大量手工编写的 SDF，总结出了一套通用的分类“约定”。例如：\n以/etc/开头的文件 -\u0026gt; 归入_config slice。 以/usr/bin/或/usr/sbin/开头的文件 -\u0026gt; 归入_bins slice。 以/usr/lib*/开头且包含.so的文件 -\u0026gt; 归入_libs slice。 包含LICENSE, COPYING等字样的文件 -\u0026gt; 归入_copyright slice。 精确识别：仅靠路径还不够。比如，在/usr/bin目录下，既有真正的二进制可执行文件，也可能混杂着 Shell 脚本或 Bash 内建命令的占位符。为了精确区分，我的分类器会调用 Linux 的file命令对每个文件进行“身份鉴定”。只有file命令确认是“ELF executable”的文件，才会被归入_bins slice，从而保证了分类的准确性。\n通过这个分类器，我们就能自动地将一个 RPM 包内的上百个文件，有条不紊地分配到不同的slices中。\nSlice 依赖分析原理 依赖分析就是找出每个 Slice（尤其是_bins和_libs）依赖了哪些外部的 Slice。\n这是技术上最关键的一步。一个二进制文件运行时，需要操作系统动态链接器加载它所依赖的共享库（.so文件），我需要自动追溯这条“依赖链”。\n我的依赖分析器采用了一个三步走的策略，来模拟动态链接器的行为：\n静态解析“需求”：对于_bins和_libs中的每个 ELF 文件，我使用readelf -d命令。这是一个静态分析工具，它能安全地读取文件头，并列出这个文件在运行时“需要 (NEEDED)”哪些共享库。例如，readelf会告诉我们brotli的库需要libc.so.6。\n全系统“寻址”：知道了需要libc.so.6，下一步就是要在系统中找到它。我通过查询ldconfig -p维护的系统库缓存，可以快速地将一个库名（libc.so.6）映射到它在文件系统上的绝对路径（例如/usr/lib64/libc.so.6）。\n反向“溯源”：拿到了库文件的绝对路径，最后一步就是确定它的“主人”。我使用rpm -qf \u0026lt;文件路径\u0026gt;命令，它可以精确地反向查询出这个文件是由哪个 RPM 包提供的。例如，rpm -qf /usr/lib64/libc.so.6会返回glibc。\n至此，完整的依赖链就建立起来了：brotli_libs -\u0026gt; (需要libc.so.6) -\u0026gt; (位于/usr/lib64/libc.so.6) -\u0026gt; (属于glibc包) -\u0026gt; (因此依赖glibc_libs)。\n通过自动化这个流程，我的工具就能为每个 Slice 精确地填充出它的deps列表。\n无法逾越的环境依赖 当我完成了上述完整的自动化流水线，并满怀信心地在一个最小化的 openEuler 环境上进行测试时，我遇到了第一个真正的挑战。\n我的依赖分析器在第 2 步“全系统寻址”时失败了！原因很简单：我测试用的这个最小化系统里，根本就没有预装待分析包所需要的所有依赖库。\n这个问题是致命的。它意味着我的工具能否成功运行，完全取决于它所在的宿主环境是否“恰好”是完备的。这对于一个追求自动化和可靠性的工具来说，是不可接受的。\n引入 Docker“沙箱化”分析 在 PR review 的过程中，华为鲁卫军老师建议我使用 chroot 或容器技术来隔离分析环境，避免安装待分析的 RPM 包污染宿主机环境。基于这个建议，我采用 Docker 实现了环境隔离，新的流程是这样的：\n构建基础镜像：编写了一个 Dockerfile，它会预先构建一个包含了 splitter 工具本身，以及所有依赖（如 python-dnf, binutils 等）的“SDF 生成器基础镜像”。\n隔离的分析流程: 当运行 gen-sdf-docker.sh 时：\n它会自动使用上述的基础镜像启动一个干净、一次性的 Docker 容器。 在容器内部，它只执行必要的操作：dnf install 来安装待分析包及其运行时依赖。 然后调用 splitter gen 命令执行核心的分析逻辑。 分析结束后，容器会被自动销毁，对用户的宿主系统环境无影响。\n意外的惊喜：第一个成功合并的 PR 竟是“副产品”！ 为了实现上述的 Docker 化流程，我需要一个包含了splitter工具本身的基础镜像。这时，鲁老师又给了我一个的建议：\n构建 splitter 的 Dockerfile 可以提交到 openEuler 的官方镜像仓库去 https://gitee.com/openeuler/openeuler-docker-images\n这让我意识到，这个为了我自己的工具而制作的镜像，本身就可以成为一个交付给社区的“官方应用镜像”！于是，我仔细阅读了官方镜像的贡献指南，编写了Dockerfile和相关的元数据，并提交了PR 到 openeuler-docker-images 仓库。\n没想到，这个作为我主线任务“副产品”的 PR，竟然先一步通过了审核，正式合并！那一刻的喜悦难以言表。我的第一个被大型开源项目合并的 PR，就这样诞生了！\n主线达成：为华为基础软件贡献代码！ 有了官方镜像的加持，我为 splitter 增加 gen 命令的PR也很快被顺利合并了，这标志着我的开源之夏项目取得了阶段性的成功。\n这次的感觉又有所不同。虽然我自己在 GitHub 上也发布过一些个人项目，但为 openEuler/splitter 这样重量级的基础软件贡献核心代码，意义完全不一样。它服务于整个 openEuler 的云原生生态，背后是华为和众多社区开发者的努力。能够成为其中一员，哪怕只是贡献了一小部分，也让我感到无比自豪。\n后续工作 开源贡献不是一次性的，而是一个持续迭代的过程。在核心功能合并后，我立刻投入到了后续的优化工作中：\n提供便携的工具入口：我提交了新的 PR #20，为项目增加了一个splitter-docker.sh脚本。它封装了所有 Docker 操作，让任何用户都可以通过一条简单的命令，使用官方镜像来运行splitter的cut和gen命令，极大地降低了使用门槛。 在写文章的过程中，这个 PR 也审核通过，成功合并了！\n更新官方镜像：随着splitter的版本迭代（比如gen命令的加入），官方镜像也需要更新。我提交了新的 PR #1023来将镜像中的splitter版本升级到最新。 文章还没发布，这个 PR 也审核通过，成功合并了！\n这让我深刻体会到，一个功能的完成，往往是另一个优化的开始。\n结语 这次开源之夏的经历，让我从一个开源的旁观者，变成了一个真正的参与者和贡献者。我不仅学到了如何设计和实现一个健壮的工具，更学会了如何在社区中沟通、协作，以及如何遵循大型项目的规范和流程。\n感谢开源之夏提供了这么好的平台，感谢 openEuler 社区的开放和包容，更要感谢我的导师鲁卫军老师的一路悉心指导。这段旅程才刚刚开始，未来，我希望能为开源世界贡献更多力量。\n","date":"2025-08-21T10:48:37+08:00","permalink":"https://mahaoliang.tech/p/%E6%88%91%E5%9C%A8%E5%BC%80%E6%BA%90%E4%B9%8B%E5%A4%8F%E4%B8%BA-openeuler-%E6%8F%90%E4%BA%A4%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA-pr-%E8%A2%AB%E5%90%88%E5%B9%B6%E4%BA%86/","title":"我在开源之夏为 openEuler 提交的第一个 PR 被合并了！"},{"content":"作为开发者，我们经常需要通过 SSH 连接到远程 Linux 服务器进行开发。工具如 VS Code 的 Remote-SSH 插件，让我们几乎感觉不到自己是在一台远程机器上工作。但一个常见的痛点随之而来：SSH 密钥管理。\n我们希望：\n使用 SSH 密钥登录服务器，并向 Git 仓库（如 GitHub）推送代码。 对每一次 Git 提交进行签名，以验证提交的来源。 最重要的一点：不希望将包含私钥的任何文件拷贝到远程服务器上，以防服务器被入侵导致私钥泄露。 幸运的是，通过 1Password 内置的 SSH Agent 和 SSH Agent Forwarding 技术，我们可以完美地解决这个问题。本文将带你一步步配置，实现安全、无缝的远程开发流程。\n核心概念简介 在开始之前，我们先简单了解几个关键概念：\nSSH Agent (SSH 代理)：它就像一个临时的密钥管理员。你可以在会话开始时，将解密的私钥（decrypted private key）加载到 Agent 中。之后，任何需要使用该密钥的 SSH 操作都会向 Agent 请求，而无需你反复输入密码。当你关闭终端会话时，Agent 也会随之关闭，密钥被安全地清除。\n1Password SSH Agent：1Password 8 及以上版本内置了一个功能强大的 SSH Agent。它将你的 SSH 私钥安全地存储在 1Password 保管库中，并通过一个安全的套接字文件（socket file）与你的系统交互。这意味着你的私钥永远不会以明文形式存在于磁盘上，所有使用请求都需要经过 1Password 的授权（例如 Touch ID 或主密码）。\nSSH Agent Forwarding (SSH 代理转发)：这是一个非常强大的 SSH 功能。当你从本地电脑 SSH 到远程服务器时，它可以建立一个安全通道，将远程服务器上需要密钥认证的操作请求，“转发”回你的本地电脑，交由你本地的 SSH Agent 来处理。这样一来，远程服务器本身完全不需要存储任何私钥。\n我们的目标流程 在本地电脑上，1Password 管理着我们的 SSH 私钥。 通过 VS Code Remote-SSH 或终端连接到远程服务器，并启用 Agent Forwarding。 在远程服务器上，执行 git push 时，认证请求被转发回本地，由 1Password 处理。 在远程服务器上，执行 git commit 时，签名请求也被转发回本地，由 1Password 处理和授权。 配置流程 前提条件 你已经安装了 1Password 8 或更高版本的桌面客户端。 你的 SSH 密钥已经创建并保存在 1Password 的 SSH 密钥 分类中。 第一步：配置本地电脑，让 SSH 使用 1Password 首先，我们需要告诉本地的 SSH 客户端，让它把所有密钥相关的请求都交给 1Password 处理。\n在 1Password 中启用 SSH Agent\n打开 1Password 桌面应用。 进入 设置 -\u0026gt; 开发者。 勾选 使用 SSH 代理。 配置本地 SSH 配置文件 (~/.ssh/config)\n参考 1password 的官方文档，我们有两种方式告诉 SSH 客户端 Agent 在哪里：IdentityAgent 指令和 SSH_AUTH_SOCK 环境变量。推荐使用 IdentityAgent。\n编辑你本地电脑上的 ~/.ssh/config 文件（如果不存在，请创建它）。在文件顶部添加以下内容：\n1 2 3 # 告诉所有 SSH 连接 (*) 都使用 1Password 的 Agent Host * IdentityAgent \u0026#34;~/Library/Group Containers/2BUA8C4S2C.com.1password/t/agent.sock\u0026#34; 验证配置\n在本地电脑的终端里运行以下命令：\n1 ssh-add -l 如果配置成功，它会列出你在 1Password 中存储的所有 SSH 密钥的公钥指纹。这证明你的本地 SSH 客户端已经成功与 1Password 对接。\n第二步：配置连接，启用 Agent Forwarding 现在，我们需要在连接到特定远程服务器时，启用 Agent Forwarding 功能。最佳实践依然是修改 ~/.ssh/config 文件。\n继续编辑你本地电脑上的 ~/.ssh/config 文件，为你的服务器添加一个专有配置块：\n1 2 3 4 5 # 给你的远程服务器起一个别名，方便连接 Host my-dev-server HostName \u0026lt;your_server_ip_or_domain\u0026gt; User mahaoliang ForwardAgent yes # \u0026lt;-- 关键！启用 Agent Forwarding Host my-dev-server: 这是你连接时使用的快捷别名。 HostName: 服务器的实际 IP 或域名。 User: 你在服务器上的用户名。 ForwardAgent yes: 这就是开启 Agent Forwarding 的开关。 现在，你可以通过 ssh my-dev-server 或在 VS Code Remote-SSH 中直接连接到 my-dev-server，转发功能会自动启用。\n第三步：配置远程服务器上的 Git 这是最后一步，也是最关键的一步。我们需要告诉远程服务器上的 Git，如何使用我们转发过来的 SSH Agent 进行提交签名。\n连接并验证转发\n首先，连接到你的远程服务器：\n1 ssh my-dev-server 连接成功后，在远程服务器的终端上，再次运行验证命令：\n1 ssh-add -l 如果 Agent Forwarding 正常工作，这里显示的输出应该和你本地电脑的输出完全一样！\n如果提示“Could not open a connection to your authentication agent.”，请检查 SSH 服务配置，确保 AllowAgentForwarding yes 已启用。\n使用 vim 打开 /etc/ssh/sshd_config 文件，找到 AllowAgentForwarding 配置项，设置为 yes：\n1 AllowAgentForwarding yes 保存后重启 SSH 服务使配置生效：\n1 systemctl restart sshd 再次连接你的远程服务器，执行 ssh-add -l，确认 Agent Forwarding 正常工作。\n获取用于签名的公钥\nGit 需要知道用哪个具体的密钥来签名。我们需要提供完整的公钥字符串作为标识。在远程服务器上运行：\n1 ssh-add -L 这个命令会列出 Agent 中所有密钥的完整公钥。复制你想要用来签名的那一行，它看起来像这样： ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICxxxxxxxxxxxxxxxxxxxx your-key-comment\n配置远程服务器的 .gitconfig\n现在，编辑你远程服务器上的 ~/.gitconfig 文件。将你原来的配置更新如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 [user] email = mahaoliang@gmail.com name = mahaoliang # 将 signingkey 的值设置为你上一步复制的完整公钥字符串 signingkey = ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICxxxxxxxxxxxxxxxxxxxx your-key-comment [gpg] # 告诉 Git 使用 ssh 程序进行签名 format = ssh [commit] # 让所有提交都默认进行签名 gpgsign = true 最重要的改动在于 signingkey。我们不再使用一个文件路径，而是直接提供了公钥本身。这让 Git 可以直接向转发过来的 Agent 请求使用这个特定的密钥进行签名。\n大功告成！来测试一下吧 一切准备就绪！在远程服务器上，进入你的任意一个 git 项目，尝试创建一个新提交：\n1 git commit --allow-empty -m \u0026#34;Test: Signed commit with 1Password Agent Forwarding\u0026#34; 此时，奇妙的事情发生了：你的本地电脑上会弹出 1Password 的授权请求，提示你应用正在请求使用你的 SSH 密钥。通过 Touch ID 或输入主密码授权后，远程服务器上的 git commit 命令瞬间完成。\n最后，检查一下你的提交日志：\n1 git log --show-signature -1 你将会看到类似下面的输出，Good signature 明确告诉你，这次提交已经由你的密钥成功签名！\n1 2 3 4 5 6 commit \u0026lt;commit_hash\u0026gt; (HEAD -\u0026gt; main) Good \u0026#34;git\u0026#34; signature for mahaoliang@gmail.com with ED25519 key SHA256:GKaU0ZCgehQ73X... Author: mahaoliang \u0026lt;mahaoliang@gmail.com\u0026gt; Date: ... Test: Signed commit with 1Password Agent Forwarding 总结 下图展示了使用 1Password 和 SSH Agent Forwarding 进行远程 Git 提交签名的核心流程。\n图中组件\n本地电脑 (Local)\n开发者：操作的发起者。 1Password SSH Agent：安全存储私钥，并处理所有签名请求。 SSH Client：本地的 SSH 程序，配置为使用 1Password Agent 并启用转发。 远程服务器 (Remote)\n远程终端：开发者在服务器上的工作界面。 Git：版本控制工具，配置为使用 SSH 进行签名。 SSH Daemon：服务器上的 SSH 服务，负责建立安全连接和转发请求。 交互流程详解\n发起提交：开发者在远程终端中执行 git commit 命令。 请求签名：Git 根据配置，向 SSH 服务请求使用密钥进行签名。 转发请求：远程服务器的 SSH Daemon 将签名请求通过加密的 SSH 隧道转发回本地电脑的 SSH Client。这是 Agent Forwarding 的核心。 请求 1Password：本地的 SSH Client 将请求交给 1Password SSH Agent。 请求用户授权：1Password 在本地电脑上弹出提示，向开发者请求授权。 用户授权：开发者在本地进行身份验证（如 Touch ID 或主密码）。 返回签名：授权成功后，1Password 生成签名并返回给本地 SSH Client。 返回签名至远程：签名通过 SSH 隧道被安全地传回远程服务器的 SSH Daemon。 完成提交：远程的 Git 进程收到有效的签名，成功创建提交，并在远程终端中显示成功信息。 通过以上配置，我们构建了一个既安全又便捷的远程开发工作流。你的私钥始终安全地躺在本地的 1Password 保管库中，而远程服务器上的所有 Git 操作（认证和签名）都能够无缝、安全地使用它。这不仅提升了安全性，也大大简化了多服务器环境下的密钥管理，让你能更专注于编码本身。\n","date":"2025-07-29T21:05:21+08:00","permalink":"https://mahaoliang.tech/p/%E4%BD%BF%E7%94%A8-1password-%E5%92%8C-ssh-agent-forwarding-%E6%8F%90%E5%8D%87%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E4%BD%93%E9%AA%8C/","title":"使用 1Password 和 SSH Agent Forwarding 提升远程开发体验"},{"content":"过去一个月，密集学习了各种 Python 相关的工具。\n在我看来，Python 的知识分为两个方面，一个是 Python 语言本身，要学习它的语法，掌握基本数据结构，了解常用的模块，总之就是会写 Python 代码，解决实际问题。\n另一个方面，是 Python 工程方面的知识。所谓工程，就是在开发大型项目时，如何让开发过程更高效：项目复杂了，如何组织代码结构；如何进行依赖管理；如何多人协作；如何做项目间隔离，避免依赖冲突；如何管理多个版本的 Python；如何构建、发布自己写的模块等等。总之就是，除了写代码之外，如何做，让开发 Python 的过程更高效。\n学习的过程中，写了一系列的技术文章。从最开始用 pyenv 管理多版本，venv 和 Conda 管理虚拟环境，到阶段性的总结了虚拟环境工具选择建议，之后深入技术实现原理，探讨了虚拟环境底层实现原理 和 Python 与 pip 的关系，之后总结了 Python 项目管理的发展历程。\n到今天，是这个系统的最后一篇：因为我会用 uv 代替前面介绍的所有工具，用 uv 管理 Python 项目的全流程。我决定了，以后的 Python 项目，都使用 uv 管理。\nuv 简介 uv 是一个用 Rust 编写的 Python 打包和项目管理器，它将多个 Python 工具（如 pip、venv、pyenv 等）的功能整合到一个工具中，提供了一个统一、高效的 Python 开发流程。\n实际上，uv 的实现并不是完全从头开始，而是对 venv 和 pip 的高级封装，对使用者提供更简单、更统一的接口。\n本文将从零开始，使用 uv 完整地走完一个项目的开发、构建和安装流程。\n安装 uv 使用官方脚本安装 推荐参考uv 项目文档，使用官方脚本安装：\n1 2 3 4 5 # macOS and Linux curl -LsSf https://astral.sh/uv/install.sh | sh # Windows powershell -ExecutionPolicy ByPass -c \u0026#34;irm https://astral.sh/uv/install.ps1 | iex\u0026#34; 脚本执行成功后，新开一个 shell，执行 uv --version 命令，查看是否安装成功。\n1 2 ❯ uv --version uv 0.8.3 (7e78f54e7 2025-07-24) PATH 环境变量 uv 被安装到用户目录的 .local/bin 目录下。\n安装脚本会自动在 .zshrc 或 .bashrc 增加配置，将 $HOME/.local/bin 添加到 $PATH 环境变量中。\n1 2 3 $ cat $HOME/.zshrc ... . \u0026#34;$HOME/.local/bin/env\u0026#34; 查看.local/bin/env ，文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 #!/bin/sh # add binaries to PATH if they aren\u0026#39;t added yet # affix colons on either side of $PATH to simplify matching case \u0026#34;:${PATH}:\u0026#34; in *:\u0026#34;$HOME/.local/bin\u0026#34;:*) ;; *) # Prepending path in case a system-installed binary needs to be overridden export PATH=\u0026#34;$HOME/.local/bin:$PATH\u0026#34; ;; esac 可以看出，.zshrc 中这行命令 . \u0026quot;$HOME/.local/bin/env\u0026quot; 的作用，是将 $HOME/.local/bin 添加到 $PATH 中。\nShell 自动补全 建议为 uv 命令启用 shell 自动补全功能：\n1 2 3 4 5 # zsh echo \u0026#39;eval \u0026#34;$(uvx --generate-shell-completion zsh)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # bash echo \u0026#39;eval \u0026#34;$(uvx --generate-shell-completion bash)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 升级 uv 通过官方脚本安装 uv 后，可按需自行更新：\n1 uv self update Python 版本管理 可以使用 uv python list 命令查看 uv 支持的所有 Python 版本：\n1 2 3 4 5 6 7 8 9 ❯ uv python list cpython-3.14.0rc1-macos-aarch64-none \u0026lt;download available\u0026gt; cpython-3.13.5-macos-aarch64-none \u0026lt;download available\u0026gt; ... cpython-3.9.6-macos-aarch64-none /usr/bin/python3 ... pypy-3.8.16-macos-aarch64-none \u0026lt;download available\u0026gt; ... graalpy-3.8.5-macos-aarch64-none \u0026lt;download available\u0026gt; uv 会列出所用可用版本，包括系统自带的 Python。\n我们可以指定安装某个版本 Python 版本：\n1 ❯ uv python install cpython-3.13.5 命令执行成功后，Python 将被安装到 ~/.local/bin 目录下：\n1 2 3 4 5 6 7 ❯ ll ~/.local/bin total 73784 -rw-r--r-- 1 haoliangma staff 328B 7 25 21:01 env -rw-r--r-- 1 haoliangma staff 165B 7 25 21:01 env.fish lrwxr-xr-x 1 haoliangma staff 89B 7 25 21:07 python3.13 -\u0026gt; /Users/haoliangma/.local/share/uv/python/cpython-3.13.5-macos-aarch64-none/bin/python3.13 -rwxr-xr-x 1 haoliangma staff 36M 7 25 05:09 uv -rwxr-xr-x 1 haoliangma staff 328K 7 25 05:09 uvx 可以看到，在 ~/.local/bin 目录下建立了符号链接（Symbolic Link），指向 Python 的实际安装位置 ~/.local/share/uv/python。\n值得注意的是，符号链接名称带了具体的版本号 python3.13，也就是说，当前的 python3 命令，仍然是系统自带的 Python 环境。\n1 2 ❯ which python3 /usr/bin/python3 因为我们在项目中都会使用虚拟环境，所以并不在乎全局环境的 Python。这里我们使用 uv 安装的 Python，并不设置为全局环境，只供以后项目的虚拟环境使用。\n后面还会看到，我们可以在 ~/.local/bin 目录下安装可以独立运行的 Python 工具，而这些工具也自带了完整环境，并不会用到全局环境的 Python，工具之间的环境也是完全隔离的。\n项目开发 创建项目 使用 uv init 命令可以快速初始化一个项目。我们可以指定项目名称，init 命令会自动创建项目目录，并生成项目结构。\n1 2 ❯ uv init -p 3.13 skycmd Initialized project `skycmd` at `/Users/haoliangma/Documents/works/skycmd` 实际上，我们不必在上一步安装 Python，因为在项目初始化的时候，如果 -p 参数指定的 Python 版本不存在，uv 会自动下载并安装。\n我们也可以在一个空的项目目录中执行 uv init 命令，这时会使用目录名作为项目名。\n1 2 3 4 5 ❯ mkdir skycmd skycmd ❯ cd skycmd ❯ uv init -p 3.11 Initialized project `skycmd` 在初始化的项目目录下，.python-version 文件会记录项目的 Python 版本号。\npyproject.toml 是最核心的项目配置文件，项目元数据、依赖项、构建配置等等都定义在这里。\n运行初始化项目 uv init 为我们生成一个示例程序 main.py，使用 uv run 命令运行：\n1 2 3 4 ❯ uv run main.py Using CPython 3.13.5 Creating virtual environment at: .venv Hello from skycmd! 第一次运行项目，会自动创建虚拟环境 .venv。\n添加依赖 我准备做一个查看天气的命令行工具，会用到 requests 处理 HTTP 请求，并使用 click 解析命令行参数。\n使用 uv add 命令添加依赖：\n1 2 uv add requests uv add click 注意，不用执行 source .venv/bin/activate 显示的激活虚拟环境，uv 会自动将依赖安装到虚拟环境中。\n安装的依赖，会自动记录在 pyproject.toml 文件中。\n1 2 3 4 dependencies = [ \u0026#34;click\u0026gt;=8.2.1\u0026#34;, \u0026#34;requests\u0026gt;=2.32.4\u0026#34;, ] 使用 uv + pyproject.toml 的方式管理依赖，和使用 pip + requirements.txt 的方式有本质区别。\npyproject.toml 只会记录直接依赖，而 requirements.txt 会记录所有依赖，包括直接依赖和间接依赖。\n这两种方式的区别，在移除依赖项时就体现出来了：\n使用 uv remove requests，会移除 requests 和所有 requests 的依赖项。 而 pip uninstall requests 只会移除 requests，留下了 requests 的依赖项。 配置构建工具 uv 支持多种构建打包工具，这里我们使用常见的 setuptools。\n参考 setuptools 的官方文档，在 pyproject.toml 中添加 build-system 配置：\n1 2 3 [build-system] requires = [\u0026#34;setuptools\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; Python 不是脚本吗，为什么还要构建打包呢？\n首先，因为我们的项目不可能总是一个简单的脚本，随着项目的复杂，可能会分为多个模块，每个模块提供独立、完整的功能。同时，项目还可以作为库发布出去，就像 requests 一样，让别人使用。这时，我们不可能将一个个的 Python 文件发给别人，而是需要使用一个构建打包工具，将我们的项目打包，方便别人安装使用。\n另外，就算不发给别人使用，如果配置了 [build-system]，在开发阶段，我们不必使用 pip install -e . 在虚拟环境安装项目自身模块，而是直接使用 uv run \u0026lt;project_name\u0026gt; 命令就可以运行整个项目。\n源码目录结构 setuptools 在构建时，会按照约定的源码目录结构，自动发现 Python 文件进构打包构建。\nsetuptools 默认支持两种源码目录布局：src-layout 和 flat-layout。也就是说，按照这两种方式放置 Python 文件，不必做额外的配置，setuptools 都能自动找到。\n我们使用简单的 flat-layout，调整项目目录结构如下：\n1 2 3 4 5 6 7 8 skycmd ├── pyproject.toml ├── ... └── skycmd/ ├── __init__.py ├── main.py └── weather/ └── __init__.py 这里有几点说明请注意：\n首先，在项目的根目录下，创建与项目同名的目录 skycmd，用来存放 Python 源码。注意，项目的根目录名，根目录下存放源码的目录名，都要跟 pyproject.toml 定义的项目名称保持一致。\n将 uv 生成的 main.py，从项目根目录，移到源码目录 skycmd 下，作为项目执行入口。\n在 skycmd 目录下，可以创建子目录，作为子模块。例如可以创建 weather 目录，用于放置获取天气信息的模块代码。\n源码目录及其子目录，每层目录下都要建一个空的 __init__.py 文件。因为目录下如果有 __init__.py 文件，Python 会认为它是一个模块。有了 __init__.py 文件，每层目录都会被自动识别为模块。\n配置项目执行入口 在 pyproject.toml 文件中，添加 [project.scripts] 配置项，指定项目执行入口。\n1 2 [project.scripts] skycmd = \u0026#34;skycmd.main:main\u0026#34; skycmd.main:main 表示 skycmd 模块下的 main.py 文件中的 main 函数。\n现在可以使用 uv run skycmd 命令来运行项目了：\n1 2 3 4 ❯ uv run skycmd Built skycmd @ file:///Users/haoliangma/Documents/works/skycmd Installed 1 package in 7ms Hello from skycmd! 因为前面我们前面配置了构建工具，现在又配置了执行入口，在运行 uv run skycmd 时，会自动进入虚拟环境，构建，将构建的包安装到虚拟环境，然后运行项目。\n注意，整个过程，我们都只使用了 uv 命令，没有显示的执行 source .venv/bin/activate 命令来激活虚拟环境，uv 命令会自动激活虚拟环境。\n同时，我们指定的是执行入口 skycmd，而不再是 main.py。\n现在看好像差别不大，但如果项目包含了多个模块，uv run skycmd 命令会自动将项目的所有模块安装到虚拟环境，然后运行入口函数：skycmd 模块的 main.py 文件中的 main 函数。如何运行的是 main.py，将不会自动安装项目自身编写的模块。\n开发服务模块 搭建好了整个项目结构，我们可以开发提供获取天气信息的模块。\n实现很简单，构建 HTTP 请求访问 wttr.in ，提供城市名作为参数，HTTP 响应内容就是城市天气信息。\n在 skycmd/weather 目录下，创建 service.py 文件，并添加如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import requests def get_weather_from_wttr(city_name): try: url = f\u0026#34;https://wttr.in/{city_name}?m\u0026amp;format=3\u0026#34; response = requests.get(url, timeout=10) response.raise_for_status() return response.text.strip() except requests.exceptions.RequestException as e: return f\u0026#34;Error getting weather information: {e}\u0026#34; def get_detailed_weather_from_wttr(city_name): try: url = f\u0026#34;https://wttr.in/{city_name}?m\u0026#34; response = requests.get(url, timeout=10) response.raise_for_status() return response.text except requests.exceptions.RequestException as e: return f\u0026#34;Error getting detailed weather information: {e}\u0026#34; if __name__ == \u0026#34;__main__\u0026#34;: weather_info = get_weather_from_wttr(\u0026#34;Shenzhen\u0026#34;) print(weather_info) 记得要在 skycmd/weather 目录下要创建一个空的 __init__.py 文件。当前的目录结构如下：\n1 2 3 4 5 6 7 8 9 skycmd ├── pyproject.toml ├── ... └── skycmd/ ├── __init__.py ├── main.py └── weather/ ├── __init__.py └── service.py 我们可以在 skycmd/weather/server.py 中添加测试方法，使用 uv run 运行该模块，验证编写的服务。\n1 2 ❯ uv run skycmd/weather/service.py Shenzhen: ⛅️ +34°C 开发入口程序 获取天气信息的模块已经完成，现在我们编写入口程序。\n修改 skeycmd/main.py文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import requests import os import sys import click from skycmd.weather.service import get_weather_from_wttr, get_detailed_weather_from_wttr @click.command() @click.argument(\u0026#39;city\u0026#39;, type=str, required=False) @click.option(\u0026#39;-v\u0026#39;, \u0026#39;--verbose\u0026#39;, is_flag=True, help=\u0026#39;显示详细天气信息\u0026#39;) def main(city, verbose): \u0026#34;\u0026#34;\u0026#34; 命令行天气工具 - 获取指定城市的天气信息 \\b 使用示例： skycmd # 获取帮助信息 skycmd Shenzhen # 获取深圳的天气 skycmd -v Shenzhen # 获取深圳的详细天气信息 \u0026#34;\u0026#34;\u0026#34; if not city: # 如果没有提供城市名，显示帮助信息 ctx = click.get_current_context() click.echo(ctx.get_help()) ctx.exit() if verbose: # 显示详细天气信息 weather_info = get_detailed_weather_from_wttr(city) print(weather_info) else: # 显示简单天气信息 weather_info = get_weather_from_wttr(city) print(weather_info) if __name__ == \u0026#34;__main__\u0026#34;: main() 现在可以使用 uv run skycmd 运行项目：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ❯ uv run skycmd Usage: skycmd [OPTIONS] [CITY] 命令行天气工具 - 获取指定城市的天气信息 使用示例： skycmd # 获取帮助信息 skycmd Shenzhen # 获取深圳的天气 skycmd -v Shenzhen # 获取深圳的详细天气信息 Options: -v, --verbose 显示详细天气信息 --help Show this message and exit. ❯ uv run skycmd Shenzhen Shenzhen: ⛅️ +34°C 因为前面已经在 pyproject.toml 中配置了执行入口 skycmd = \u0026quot;skycmd.main:main\u0026quot;，所以使用 uv run 的时候，指定的是 skycmd，而不是 Python 文件名 main.py。\n现在我们简单的修改一下程序，增加显示简单天气时的输出内容：\n1 2 3 4 # 显示简单天气信息 weather_info = get_weather_from_wttr(city) print(f\u0026#34;🌍 天气信息：\u0026#34;) print(weather_info) 修改完成后，再次使用 uv run skycmd Shenzhen 运行，可以查看到改动后的效果：\n1 2 3 ❯ uv run skycmd Shenzhen 🌍 天气信息： Shenzhen: ⛅️ +34°C 完美！开发过程顺畅丝滑。\n构建和安装工具 如果想使用我们开发的命令行工具 skycmd，必须每次都要到项目目录下运行 uv run skycmd，这样有点麻烦。\n我们可以先使用 uv build，将整个项目打包成标准的 Python 包：\n1 2 3 4 5 ❯ uv build Building source distribution... ... Successfully built dist/skycmd-0.1.0.tar.gz Successfully built dist/skycmd-0.1.0-py3-none-any.whl 可以看到，构建成功后，在 dist 目录下生成了两个文件：\nskycmd-0.1.0.tar.gz：源代码分发包 skycmd-0.1.0-py3-none-any.whl：二进制分发包 接着可以使用 uv tool install 命令，将 skycmd 安装到用户目录：\n1 2 3 4 5 6 7 8 9 10 11 12 ❯ uv tool install dist/skycmd-0.1.0-py3-none-any.whl Resolved 7 packages in 563ms Prepared 1 package in 4ms Installed 7 packages in 7ms + certifi==2025.7.14 + charset-normalizer==3.4.2 + click==8.2.1 + idna==3.10 + requests==2.32.4 + skycmd==0.1.0 (from file:///Users/haoliangma/works/skycmd/dist/skycmd-0.1.0-py3-none-any.whl) + urllib3==2.5.0 Installed 1 executable: skycmd tool install uv tool install 安装的是二进制分发包 dist/skycmd-0.1.0-py3-none-any.whl。\n命令执行成功，将在 ~/.local/bin 目录下生成 skycmd 命令。\n1 2 3 4 5 ❯ ll ~/.local/bin ... lrwxr-xr-x 1 haoliangma staff 57B 7 25 22:34 skycmd -\u0026gt; /Users/haoliangma/.local/share/uv/tools/skycmd/bin/skycmd -rwxr-xr-x 1 haoliangma staff 36M 7 25 05:09 uv -rwxr-xr-x 1 haoliangma staff 328K 7 25 05:09 uvx 这个 skycmd 是一个符号链接，指向 ~/.local/share/uv/tools/skycmd/bin/skycmd。\n所以，skycmd 工具的实际文件存放在 ~/.local/share/uv/tools/skycmd/目录中。查看这个目录的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 ❯ tree -L 2 ~/.local/share/uv/tools/skycmd/ /Users/haoliangma/.local/share/uv/tools/skycmd/ ├── bin │ ├── activate │ ├── ... │ ├── python -\u0026gt; /Users/haoliangma/.local/share/uv/python/cpython-3.13.5-macos-aarch64-none/bin/python3.13 │ └── skycmd ├── CACHEDIR.TAG ├── lib │ └── python3.13 ├── pyvenv.cfg └── uv-receipt.toml 可以看出，这个目录包含了一个完整的 Python 虚拟环境。所以虽然 skycmd 安装到了用户目录，但它使用自己的虚拟环境，指定了 Pythonn 版本，依赖也安装在自己的环境中。这样，工具之间的环境是完全隔离的，不会相互影响。\n现在，可以在命令行中使用 skycmd 命令了：\n1 2 3 ❯ skycmd Shenzhen 🌍 天气信息： Shenzhen: ⛅️ +29°C 不想用了，记得删除：\n1 2 ❯ uv tool uninstall skycmd Uninstalled 1 executable: skycmd 完美！\n总结 本文详细记录了使用 uv 管理 Python 项目的全流程（虽然没有讲到模块发布）。\nuv 会自动创建虚拟环境，执行 uv 命令会自动在虚拟环境中运行，不需要显示的激活。\n所以使用 uv 时要记得：一切操作都要使用 uv，最好不要 uv 和 pip 混用。\n整理本文提到的主要命令 功能 命令 描述 更新 uv self update 将 uv 更新到最新版本。 Python 版本管理 uv python list 列出所有可用的 Python 版本，包括已安装和可下载的。 uv python install \u0026lt;version\u0026gt; 下载并安装指定版本的 Python。 项目初始化 uv init -p \u0026lt;python_version\u0026gt; \u0026lt;project_name\u0026gt; 初始化一个新的 Python 项目，可指定 Python 版本并自动创建项目目录和基础文件，如 pyproject.toml。 运行代码 uv run \u0026lt;file_or_script\u0026gt; 在项目的虚拟环境中运行 Python 脚本或已配置的入口。首次运行时会自动创建虚拟环境。 依赖管理 uv add \u0026lt;package\u0026gt; 向项目中添加依赖，并自动更新 pyproject.toml 文件。 uv remove \u0026lt;package\u0026gt; 从项目中移除依赖及其相关子依赖。 项目构建 uv build 将项目打包成标准的源代码分发包 (.tar.gz) 和二进制分发包 (.whl)。 工具安装 uv tool install \u0026lt;package_or_wheel\u0026gt; 将一个 Python 包（如本地构建的 .whl 文件）作为一个独立的命令行工具安装。uv 会为其创建一个隔离的虚拟环境。 uv tool uninstall \u0026lt;tool_name\u0026gt; 卸载已安装的命令行工具。 项目开发流程 本文通过创建一个名为 skycmd 的命令行天气查询工具，演示了使用 uv 的完整开发流程：\n初始化项目: 使用 uv init 创建项目结构和 pyproject.toml 配置文件。 添加依赖: 使用 uv add requests click 添加项目所需的第三方库。 配置构建系统: 在 pyproject.toml 中配置 setuptools 作为构建工具，以便后续的构建和打包。 组织源码: 采用 flat-layout 目录结构，将源代码放置在与项目同名的子目录中。 配置执行入口: 在 pyproject.toml 的 [project.scripts] 部分指定项目的命令行入口，使得可以使用 uv run skycmd 来运行。 开发与调试: 在开发过程中，直接使用 uv run 来测试和运行代码，uv 会自动处理环境和依赖。 构建与安装: 开发完成后，使用 uv build 将项目打包，然后使用 uv tool install 将其安装为系统级的命令行工具，方便在任何地方调用。 本文的示例代码在 GitHub，希望本文对你有帮助。\n","date":"2025-07-25T19:54:51+08:00","permalink":"https://mahaoliang.tech/p/python-%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5uv-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","title":"Python 项目管理最佳实践：uv 使用指南"},{"content":"在很长一段时间里，我管理 Python 项目的方式堪称“原始”。每当项目需要新的依赖，我便会在 README.md 文件里手动记上一笔，提醒自己需要 pip install 哪些库。这种“刀耕火种”的模式，对于个人写的一些小脚本尚可应付，但当项目变得复杂，或是需要与他人协作时，其脆弱和低效便暴露无遗。\n真正的转折点发生在今年夏天。我有幸参与了开源之夏，并成功中选了 openEuler 社区的 面向 openEuler distroless 镜像的 SDF 自动生成工具开发 项目，为 splitter 这个工具贡献代码。当我满怀激情地克隆代码库，准备大展拳脚时，一个文件赫然出现在我的眼前：pyproject.toml。这个我以往只是模糊听闻过的文件，在这里却是项目配置的核心。\n这次经历像一扇窗，让我窥见了现代 Python 项目管理的全新世界。于是，我将这段学习和探索的经历整理成文。\n传统方式：venv + requirements.txt 以 venv 和 requirements.txt 为核心的工作流，是 Python 社区在告别全局安装、走向规范化管理过程中迈出的重要一步。\n环境隔离与依赖列表 虚拟环境 (venv)\n如果你经历过在系统全局 Python 环境中安装各种包的混乱时期，你一定对 “依赖地狱” (dependency hell) 这个词深有体会。项目 A 需要 requests==2.20.0，而项目 B 依赖的另一个库却需要 requests==2.28.0，它们在全局环境中相互冲突，让开发者头痛不已。\nvenv 的出现正是为了解决这个问题。它允许我们为每个项目创建一个独立的、与全局环境隔离的 Python 工作空间。\n1 2 # 在项目根目录下，创建一个名为 .venv 的虚拟环境 python3 -m venv .venv 这个命令会创建一个 .venv 文件夹，里面包含了项目所需的一个迷你的 Python 运行环境。要使用它，我们需要先“激活”：\n1 source .venv/bin/activate 激活后，你会发现命令行提示符前面多了 (.venv) 的标识。此时，所有 pip 的安装、卸载操作都将被限制在这个独立的虚拟环境中，再也不会污染全局环境了。\n依赖文件 (requirements.txt)\n环境隔离了，但如何与他人协作呢？我们总不能把整个 .venv 文件夹都发给别人吧。这时，requirements.txt 就登上了历史舞台。它的作用，就是一份项目的“依赖清单”。\n最常见的生成方式是使用 pip freeze 命令：\n1 2 # 将当前虚拟环境中所有已安装的包及其精确版本号导出 pip freeze \u0026gt; requirements.txt 这样，你的项目协作者或者部署服务器，只需要拿到你的代码和这个 requirements.txt 文件，然后执行一条简单的命令，就可以复现出一个一模一样的运行环境：\n1 2 # 从 requirements.txt 文件中安装所有指定的依赖 pip install -r requirements.txt 这套组合拳极大地提升了 Python 项目的规范性和可复现性，至今仍有大量项目在使用。\n传统方式的隐患 尽管 venv + requirements.txt 解决了大问题，但随着项目复杂度的提升，其内在的缺陷也逐渐暴露出来。\n依赖混淆\n最大的问题在于 pip freeze 的工作方式。它像一个不加分辨的记录员，会把你环境中所有的包都记录下来。这其中既包含了你为了实现功能而主动安装的直接依赖（比如 Web 框架 Flask），也包含了 Flask 运行所必需的间接依赖（比如 Werkzeug, Jinja2, click 等）。\n最终生成的 requirements.txt 文件看起来会是这样：\n1 2 3 4 5 6 7 8 # requirements.txt blinker==1.7.0 click==8.1.7 Flask==3.0.0 itsdangerous==2.1.2 Jinja2==3.1.3 MarkupSafe==2.1.3 Werkzeug==3.0.1 在这个文件里，你已经分不清谁是谁的依赖了。项目的核心依赖关系被模糊掉了，给后续的维护，比如升级某个特定的核心库，带来了不小的麻烦。\n孤儿依赖\n另一个令人头疼的问题是“孤儿依赖”。假设你的项目后续不再需要 Flask 了，于是你执行了 pip uninstall flask。pip 很听话地卸载了 Flask 本身，但它当初为了 Flask 而自动安装的 blinker、click 等间接依赖，却被遗留在了环境中，变成了无人认领的“孤儿”。\n日积月累，你的虚拟环境会因为这些残留的孤儿依赖而变得越来越臃肿，还可能在未来引发难以预料的依赖冲突。\n正是因为这些的缺陷，Python 社区开始探索一种更清晰、更智能的管理方案。这便引出了我们下一章的主角——pyproject.toml。\n现代篇章：pyproject.toml 面对 requirements.txt 带来的依赖混淆问题，Python 社区需要一个更强大、更规范的解决方案，答案就是 pyproject.toml。\n标准的诞生 (PEP 518 \u0026amp; 621) 在 pyproject.toml 成为标准之前，一个 Python 项目的配置信息可谓“四分五裂”。项目元数据可能在 setup.py 或 setup.cfg 里，运行依赖在 requirements.txt 中，测试配置在 tox.ini 或 .coveragerc 里，代码格式化工具 black 和静态检查工具 mypy 又有它们各自的配置文件。这种碎片化的状态让项目维护变得异常繁琐。\nPEP 518 的提出正是为了终结这种乱象。它定义了一个名为 pyproject.toml 的文件格式，旨在成为所有构建工具的统一配置入口。随后，PEP 621 进一步规范了如何在这个文件中声明项目的核心元数据（如名称、版本、作者和依赖项），使其彻底摆脱了对 setup.py 的依赖。\n简单来说，pyproject.toml 的使命就是将所有与项目相关的配置，集中到一个官方认可的、格式统一的文件中。\n声明式依赖管理 pyproject.toml 最重要的改进，在于它引入了声明式依赖管理。与 pip freeze 那种不加区分的全量记录不同，我们现在只需要在 pyproject.toml 文件中清晰地声明项目的直接依赖。\n让我们回到上一章的 Flask 项目，它的 pyproject.toml 文件现在会是这样：\n1 2 3 4 5 6 7 # pyproject.toml [project] name = \u0026#34;my-flask-app\u0026#34; version = \u0026#34;0.1.0\u0026#34; dependencies = [ \u0026#34;Flask==3.0.0\u0026#34; ] 看，多么清爽！dependencies 列表里只有 Flask。我们在这里表达的是意图：“我的项目需要 Flask 3.0.0 版本”，而不是 Flask 运行所需要的所有包的冗长列表。至于 Flask 自身依赖的 Werkzeug、Jinja2 等，将由工具在安装时自动去解析和处理。\n这种方式将项目的直接依赖与间接依赖彻底分离，让依赖关系一目了然，极大地提升了项目的可读性和可维护性。\npip install . 的背后原理 现在我们有了 pyproject.toml，那么 pip 是如何利用它来安装项目的呢？\n当你进入项目根目录，在激活的虚拟环境中执行 pip install . 背后其实发生了两个关键步骤：构建和安装。这个过程不仅仅是复制文件，而是将你的项目变成一个标准的、可分发的 Python 软件包。\n第一步：构建 (Build)\npip 首先会扮演一个“构建前端”的角色。它会读取 pyproject.toml 文件中的 [build-system] 表，找到指定的“构建后端”（通常是 setuptools）。然后，pip 会指示构建后端，依据当前项目的源代码和 pyproject.toml 中的元数据，构建出一个标准的 Python 软件包，通常是一个 .whl (wheel) 文件。这个 wheel 文件是一个包含了所有代码和元数据的 zip 压缩包，是现代 Python 的标准分发格式。\n第二步：安装 (Install)\n构建完成后，pip 会接手这个新鲜出炉的 wheel 文件，并将其内容“解压”并安装到你的虚拟环境中。这个过程会产生以下三类核心产物：\n项目代码与元数据 (Project Code and Metadata) 你的项目代码（即所有的 .py 文件和包）会被复制到虚拟环境的 site-packages 目录下（例如 .venv/lib/python3.11/site-packages/my_flask_app）。\n同时，一个名为 my_flask_app-0.1.0.dist-info 的元数据目录也会被创建。你可以把它看作是这个软件包的“身份证”，里面包含了从 pyproject.toml 中提取的所有信息，比如项目名、版本、作者以及最重要的——依赖列表。\n项目依赖 (Project Dependencies) pip 会读取上述元数据文件，找到其中声明的 dependencies 列表（例如 \u0026quot;Flask==3.0.0\u0026quot;）。\n然后，它会自动下载并安装所有这些直接依赖，以及这些依赖所需要的间接依赖（如 Werkzeug, Jinja2 等），并将它们全部安装到 site-packages 目录中。\n可执行的命令行脚本 (Executable Command-line Scripts) 如果你在文件中定义了 [project.scripts] 部分，像这样：\n1 2 [project.scripts] my-app = \u0026#34;my_flask_app.cli:main\u0026#34; 那么 pip 在安装时，会在虚拟环境的 bin 目录（Windows 上是 Scripts）下创建一个名为 my-app 的可执行文件。\n这个文件是一个小小的“启动器”脚本，它的作用是调用当前虚拟环境中的 Python 解释器，并执行你指定的函数 (my_flask_app.cli:main)。\n正因为如此，一旦安装完成并激活了虚拟环境，你就可以在任何路径下直接通过命令行运行 my-app 来启动你的应用程序了。\n通过这套标准化的流程，pip install . 不仅安装了代码和依赖，还完成了命令行工具的创建，将一个项目从一堆源代码变成了一个功能完整、随时可用的工具。\n可编辑模式 (pip install -e .) pip install . 非常适合用于最终的安装和部署，但在日常开发中，每次修改代码后都重新构建和安装一遍，显然效率太低。为此，pip 提供了一种强大的可编辑模式 (editable mode)。\n1 pip install -e . -e 参数是这个模式的关键。执行这条命令后，pip 不会再把你的项目文件复制到 site-packages 目录中，而它会在 site-packages 里创建一个特殊的链接文件（.pth 文件），这个链接直接指向你当前项目的源代码目录。\n这样做的好处是显而易见的：你的项目源代码和虚拟环境中的“已安装版本”实现了实时同步。你在编辑器里对任何 .py 文件做的修改，保存后会立即生效，无需任何重新安装的步骤。这极大地简化了“修改 - 运行 - 调试”的开发循环，是现代 Python 开发的必备技巧。\n通过 pyproject.toml 和可编辑模式，我们不仅拥有了清晰的依赖管理，还获得了高效的开发体验。接下来，让我们通过一个真实的项目，来看看 pyproject.toml 在实战中是如何发挥作用的。\n解析splitter 项目的 pyproject.toml 以我参与的 splitter 项目为例，解析它的 pyproject.toml 文件，看看它是如何将项目的所有配置信息尽收囊中的。\n以下是 splitter 项目中 pyproject.toml 文件的核心内容，为便于说明，已做适当简化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # pyproject.toml of splitter project [build-system] requires = [\u0026#34;setuptools\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;splitter\u0026#34; version = \u0026#34;1.0.0\u0026#34; # Assuming a version for clarity description = \u0026#34;A tool for splitting software packages into smaller components.\u0026#34; authors = [{name = \u0026#34;openEuler Cloudnative SIG\u0026#34;}] readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.7\u0026#34; license = {text = \u0026#34;MulanPSL-2.0\u0026#34;} dependencies = [ \u0026#34;PyYAML\u0026#34;, \u0026#34;click\u0026#34;, \u0026#34;packaging\u0026#34;, \u0026#34;jinja2\u0026#34; ] [project.urls] Homepage = \u0026#34;https://gitee.com/openeuler/splitter\u0026#34; [project.scripts] splitter = \u0026#34;tools.main:main\u0026#34; [tool.setuptools.packages.find] where = [\u0026#34;.\u0026#34;] exclude = [\u0026#34;tests\u0026#34;, \u0026#34;docs\u0026#34;] 现在，让我们逐段来剖析这个文件。\n[build-system] 1 2 3 [build-system] requires = [\u0026#34;setuptools\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; 这是 pyproject.toml 的“入口”，也是遵循 PEP 518 规范的体现。它告诉 pip 这样的构建工具：在构建本项目之前，请确保你的环境中安装了 setuptools 和 wheel 这两个包，因为它们是我需要的构建工具。然后，请使用 setuptools.build_meta 这个入口点来执行实际的构建操作。\n这一段配置，实现了项目构建依赖与项目本身运行依赖的解耦。\n[project] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [project] name = \u0026#34;splitter\u0026#34; version = \u0026#34;1.0.0\u0026#34; description = \u0026#34;...\u0026#34; authors = [...] readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.7\u0026#34; license = {text = \u0026#34;MulanPSL-2.0\u0026#34;} dependencies = [ \u0026#34;PyYAML\u0026#34;, \u0026#34;click\u0026#34;, \u0026#34;packaging\u0026#34;, \u0026#34;jinja2\u0026#34; ] 这部分是项目的核心元数据，遵循 PEP 621 规范。\nname, version, description, authors：这些都是项目的基本信息，会被打包到软件中，并在 PyPI 等包索引网站上展示。\nrequires-python：这是一个非常重要的字段，它声明了项目运行所需的最低 Python 版本。如果用户尝试在一个不兼容的 Python 版本（如 Python 3.6）上安装，pip 会直接报错并终止安装，避免了后续可能出现的各种运行时错误。\ndependencies：这里是项目的依赖。它清晰地列出了 splitter 运行所必需的直接依赖项。当执行 pip install . 时，pip 会负责安装 PyYAML, click, packaging, jinja2 以及它们各自的所有子依赖，而我们无需关心这些复杂的依赖链。\n[project.scripts] 1 2 [project.scripts] splitter = \u0026#34;tools.main:main\u0026#34; 这一行配置，定义了一个名为 splitter 的命令行入口。\n当项目被安装后，pip 会在虚拟环境的 bin/ 目录下创建一个名为 splitter 的可执行文件。当我们运行这个命令时，系统会自动调用 tools/main.py 文件中的 main() 函数。这使得一个复杂的 Python 项目可以像一个普通的系统命令一样被调用，极大地提升了用户体验。\n[tool.setuptools.packages.find] 1 2 3 [tool.setuptools.packages.find] where = [\u0026#34;.\u0026#34;] exclude = [\u0026#34;tests\u0026#34;, \u0026#34;docs\u0026#34;] 前缀为 [tool.*] 的表是为各种第三方工具预留的配置空间。这里，我们为构建后端 setuptools 提供了配置。\npackages.find 指示 setuptools 自动发现项目中的所有 Python 包。where = [\u0026quot;.\u0026quot;] 告诉它从当前根目录开始查找，而 exclude = [\u0026quot;tests\u0026quot;, \u0026quot;docs\u0026quot;] 则明确排除了测试代码和文档目录，确保它们不会被打包到最终发布的应用中。\n通过这个真实的例子，我们可以看到 pyproject.toml 如何将项目的构建信息、元数据、运行依赖、命令行入口和工具配置，全部地组织在了一起，让 Python 项目的结构变得清晰和标准化。\nPoetry, UV, PDM 等高级管理工具 venv + pyproject.toml + pip 的组合，已经构建起了一个相当稳固和规范的项目管理框架，它解决了依赖隔离和声明的核心问题。然而，这个工作流依然存在一些需要开发者手动操作的环节：\n手动管理虚拟环境：你需要记得先创建，再激活。\n手动编辑依赖文件：添加或移除依赖时，你需要手动去编辑 pyproject.toml 文件。\n有没有一种工具，能将这些步骤完全自动化呢？当然有。这便是 Poetry, PDM 以及新秀 uv 这类高级项目管理工具的使命所在。\n新一代高级管理工具 这些工具并非要推翻 venv 和 pyproject.toml，恰恰相反，它们是建立在这些官方标准之上的高级封装和工作流引擎。它们的核心理念可以概括为：\n自动化环境管理：你不再需要关心 venv 的创建和激活，工具会自动为你处理好一切。\n命令式依赖操作：通过简单的命令（如 add, remove）来管理依赖，工具会自动更新 pyproject.toml 文件。\n确定性构建：通过生成一个精确的 lock 文件（如 poetry.lock, pdm.lock, uv.lock），锁定项目中所有依赖（包括直接和间接依赖）的精确版本。这确保了任何人在任何时间、任何机器上都能构建出完全一致的运行环境。\n集成化体验：将依赖管理、环境管理、打包、发布等功能集成到一套统一的命令行接口中，提供“一站式”的解决方案。\n以 uv 为例的现代化工作流 uv 是由 ruff 的作者开发的最新一代 Python 打包工具，它用 Rust 编写。让我们以 uv 为例，体验一下现代化的工作流是多么流畅。\n假设你已经通过 pip install uv 安装了它。\n开发者 A (项目创建者)\n初始化项目 在一个空目录中，我们不再需要手动创建任何文件。\n1 2 # uv 会引导你创建 pyproject.toml 文件 uv init 添加依赖 现在，想给项目添加 flask 依赖？告别手动编辑，一条命令即可：\n1 uv add flask 这条命令，uv 在背后为你完成了一系列操作：\n检查并创建虚拟环境：它会自动检测当前目录下是否存在 .venv，如果没有，就为你创建一个。\n修改 pyproject.toml：自动将 flask 添加到 [project.dependencies] 列表中。\n解析依赖并安装：解析 flask 的所有依赖树，并将它们全部安装到虚拟环境中。\n生成锁文件：创建一个 uv.lock 文件，里面精确记录了本次安装的所有包（包括间接依赖）的版本号和哈希值，锁定了当前环境的状态。\n开发者 B (协作者)\n同步环境 当开发者 B 从 GitHub 克隆了项目后，他不需要再去研究 pyproject.toml 或执行复杂的安装命令。他只需要：\n1 uv sync uv 会读取 uv.lock 文件，然后下载并安装所有被锁定的包，为他创建一个与开发者 A 完全一致的虚拟环境。\n日常开发与执行\n在开发过程中，你甚至不需要手动 source .venv/bin/activate 来激活环境。\n1 2 # uv 会自动在项目的虚拟环境中执行 python main.py uv run python main.py uv run 命令会自动寻找并使用当前项目的虚拟环境来执行后续的命令，让你的操作更加简洁。\n通过 uv 的演示，我们可以看到，现代化的项目管理工具将开发者从繁琐的、易出错的手动操作中彻底解放出来。它们通过自动化和确定性的机制，让依赖和环境管理变得简单、可靠且高效。\n好的，这是最后一章的总结部分。它将对全文进行回顾，并提炼出具体、可操作的最佳实践，为读者画上一个圆满的句号。\n构建你的现代化 Python 工作流 无论你正在开始一个新项目，还是打算重构一个旧项目，请遵循以下三个原则。\n1. 隔离是基础：始终为你的项目创建虚拟环境\n这是现代化项目管理的基石，也是最不应该被忽略的一步。为每个项目创建一个独立的虚拟环境，可以从根源上杜绝依赖冲突和全局环境污染。像 uv, Poetry, PDM 这类工具已经将这一步完全自动化，你甚至无需再手动操作。如果你仍在使用原生工具，请务必将 python -m venv .venv 作为你开启任何新项目的第一条命令。\n2. 声明是核心：拥抱 pyproject.toml，告别 requirements.txt\npyproject.toml 是 Python 项目的未来。请将它作为你项目配置的唯一真实来源。\n只声明直接依赖：在 [project.dependencies] 中，只列出你的项目代码直接 import 的那些库。这能让你的项目依赖关系保持最大程度的清晰和可维护性。\n统一所有配置：将代码检查工具 (linter)、格式化工具 (formatter)、测试框架等所有工具的配置，都迁移到 pyproject.toml 的 [tool.*] 表中，让项目根目录保持整洁。\n3. 工具是利器：选择一个现代化的管理工具\n虽然你可以手动维护 pyproject.toml 并结合 pip 使用，但一个现代化的项目管理工具能极大地提升你的生产力。\n对于新项目：强烈推荐直接使用 uv 或 Poetry。它们提供的 add, remove, sync, run 等命令，将依赖管理和环境操作的体验提升到了一个全新的高度。它们带来的确定性构建（通过 lock 文件）对于团队协作和持续集成（CI/CD）至关重要。\n对于现有项目：迁移到这些工具也比你想象的要简单。大多数工具都提供了从 requirements.txt 导入依赖的功能，可以帮助你平滑过渡。\n写在最后 希望这篇指南能够帮助你理清 Python 项目管理的脉络，并为你提供一套清晰、可行的实践方案。现在就动手，为你的下一个 Python 项目开启一个现代化的新起点吧！\n","date":"2025-07-23T18:39:02+08:00","permalink":"https://mahaoliang.tech/p/%E7%8E%B0%E4%BB%A3-python-%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%8C%87%E5%8D%97/","title":"现代 Python 项目管理指南"},{"content":"Python 与 pip 的关系 刚开始学 python 的时候，知道 python 是一个解释器，而 pip 是一个包管理器，以为它们的“地位”是平等的。然而随着了解的深入才发现，pip 本身就是一个 Python 包，它的运行，完全依赖于 python 解释器。\n简单来说，它们的关系可以这样定义：\nPython 是解释器：它是一种高级编程语言，我们编写的 .py 脚本需要通过 Python 解释器来执行，将代码转换成机器可以理解的指令。没有 Python 解释器，我们写的 Python 代码就是一堆没有生命的文本文件。\npip 是包管理器：可以把它想象成 Python 世界的“应用商店 (App Store)”。它是一个命令行工具，专门用来查找、下载、安装、卸载和管理 Python 的第三方软件包（也称为库或模块）。\n最关键的一点是：pip 本身也是一个用 Python 编写的包。这意味着 pip 的运行离不开 python 解释器的支持，它们是一个密不可分的组合，Python 提供了运行环境，而 pip 则极大地丰富 Python 的能力。\n为什么需要包管理？ 在没有包管理的早期，开发者如果想使用别人写好的代码，可能需要手动去网站下载源码压缩包，解压后自己想办法放到项目特定的目录下，如果这个代码还依赖其他代码，整个过程将成为一场噩梦。pip 的出现彻底改变了这一切：\n代码重用与效率提升：当需要实现一个复杂的功能时，比如发送网络请求，很大概率已经有非常成熟的第三方库存在了。通过一条简单的 pip install requests 命令，你就能获得强大的网络请求能力，无需从零开始编写复杂的底层代码。\n自动处理依赖关系：一个库通常会依赖其他多个库才能正常工作。例如，你安装 A 库，A 库可能需要 B 库的 1.5 以上版本和 C 库的任意版本。如果手动管理，这将变得极其繁琐且容易出错。pip 则能自动分析这些依赖关系，将所有需要的“配料”一次性、按正确的版本要求准备妥当。\n确保版本一致性：pip 允许我们将项目所有依赖包记录在一个 requirements.txt 文件中。这样，任何人在任何地方，都可以通过这个文件创建出完全相同的运行环境。\n捆绑安装 为了强调 pip 的重要性，自 Python 3.4 版本以来，官方的 Python 安装程序已经默认将 pip 捆绑在内。这意味着，当你从官方渠道下载并安装 Python 时，pip 工具也一并被安装到了你的系统中。\n精准定位：我的 Python 和 pip 在哪里？ 在日常开发中，我们常常会在电脑上安装多个版本的 Python，例如系统自带的 Python、通过 Homebrew 安装的 Python、以及使用 pyenv 等版本管理工具安装的多个 Python。这就带来了一个核心问题：当我们在终端里敲下 python3 或 pip3 命令时，我们到底在调用哪一个？\n快速定位：which 和 where 命令 最直接的定位方法是使用操作系统提供的路径查找命令。\n在 macOS 或 Linux 系统中，我们可以使用 which 命令： 1 2 3 4 5 # 查看 python3 可执行文件的路径 which python3 # 查看 pip3 可执行文件的路径 which pip3 在 Windows 系统中，对应的命令是 where： 1 2 3 4 5 # 查看 python3 可执行文件的路径 where python3 # 查看 pip3 可执行文件的路径 where pip3 这些命令会搜索系统的环境变量 PATH，并返回找到的第一个匹配的可执行文件的完整路径。\n真正的 Python 解释器在哪里？ 当你使用像 pyenv 这样的 Python 版本管理工具时，which 命令的结果可能会让你感到困惑：\n1 2 ❯ which python3 /Users/haoliangma/.pyenv/shims/python3 这个路径指向的并不是一个真实的 Python 解释器，而是一个叫做“shim”的转发脚本。当你执行 python3 命令时，实际上是这个“shim”接到了指令。它会检查你当前目录或全局设置，判断你希望使用哪个版本的 Python（例如 3.10.18），然后再将你的命令无缝地转接给那个版本对应的真实解释器。\n那么，如何才能找到真正的 Python 解释器？\n执行下面的命令，返回真实解释器路径：\n1 ❯ python3 -c \u0026#34;import sys; print(sys.executable)\u0026#34; 通过这个命令，我们可以清晰地看到真相：\n1 2 3 4 5 6 7 # 由 pyenv 管理的 Python ❯ python3 -c \u0026#34;import sys; print(sys.executable)\u0026#34; /Users/haoliangma/.pyenv/versions/3.10.18/bin/python3 # macOS 系统自带的 Python ❯ python3 -c \u0026#34;import sys; print(sys.executable)\u0026#34; /Applications/Xcode.app/Contents/Developer/usr/bin/python3 这个路径才是我们正在使用的 Python 解释器所在的位置。\n确认 pip 的真实位置 同样地，我们也需要确认 pip 的真实位置。可以使用 pip3 --version 命令：\n1 2 3 4 5 6 7 # 由 pyenv 管理的 Python ❯ pip3 --version pip 23.0.1 from /Users/haoliangma/.pyenv/versions/3.10.18/lib/python3.10/site-packages/pip (python 3.10) # macOS 系统自带的 Python ❯ pip3 --version pip 21.2.4 from /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages/pip (python 3.9) 我们还可以用 pip 自己来“调查”自己，因为 pip 本身也是一个包：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 由 pyenv 管理的 Python ❯ pip3 show pip Name: pip Version: 23.0.1 Summary: The PyPA recommended tool for installing Python packages. Home-page: https://pip.pypa.io/ Author: The pip developers Author-email: distutils-sig@python.org License: MIT Location: /Users/haoliangma/.pyenv/versions/3.10.18/lib/python3.10/site-packages Requires: Required-by: # macOS 系统自带的 Python ❯ pip3 show pip Name: pip Version: 21.2.4 Summary: The PyPA recommended tool for installing Python packages. Home-page: https://pip.pypa.io/ Author: The pip developers Author-email: distutils-sig@python.org License: MIT Location: /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages Requires: Required-by: pip install 的三个目的地 当我们执行 pip install \u0026lt;package_name\u0026gt; 时，这个包究竟被安装到哪里了？\npip install 有三个不同的目的地：全局 Site-Packages、用户 Site-Packages 和虚拟环境 Site-Packages。\n全局安装：便捷但危险的默认选项 这是最直接的安装方式，但通常也是最不推荐的方式。\n当你的全局 Python 环境拥有写入权限时（例如，使用 pyenv、Homebrew 或在 Windows 上默认安装的 Python），执行 pip install package_name，会将 package 安装到全局 site-packages 目录下。\n如何知道全局 site-packages 具体在哪里？\n可以通过 pip show 查看已安装包的位置，得知 site-packages 的位置：\n1 2 3 4 5 6 7 8 9 ❯ pip3 install pyfiglet Successfully installed pyfiglet-1.0.3 ❯ pip3 show pyfiglet Name: pyfiglet Version: 1.0.3 ... Location: /Users/haoliangma/.pyenv/versions/3.10.18/lib/python3.10/site-packages ... 输出中的 Location 字段地告诉我们，pyfiglet 被安装的具体位置。由于是在全局环境执行的安装，这个位置就是全局 site-packages 目录。\n在安装之前，你可以通过编程方式，预先知道全局 site-packages 的路径：\n1 2 ❯ python3 -c \u0026#34;import site; print(site.getsitepackages())\u0026#34; [\u0026#39;/Users/haoliangma/.pyenv/versions/3.10.18/lib/python3.10/site-packages\u0026#39;] 对于 macOS 自带的 Python，site.getsitepackages() 可能会返回一个包含多个路径的列表：\n1 2 python3 -c \u0026#34;import site; print(site.getsitepackages())\u0026#34; [\u0026#39;/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages\u0026#39;, \u0026#39;/Applications/Xcode.app/Contents/Developer/AppleInternal/Library/Python/3.9/site-packages\u0026#39;, \u0026#39;/Library/Python/3.9/site-packages\u0026#39;, \u0026#39;/AppleInternal/Library/Python/3.9/site-packages\u0026#39;, \u0026#39;/AppleInternal/Tests/Python/3.9/site-packages\u0026#39;] 这意味着 Python 在查找全局包时，会按照列表中的顺序依次搜索这些目录。这是一种分层系统，允许系统本身、Xcode 工具链以及管理员安装的包共存。\n我们应该极力避免全局安装。这种方式会“污染”你的主 Python 环境，一旦项目增多，极易导致不同项目间的依赖版本冲突。\nmacOS 系统自带的 Python，普通用户没有权限进行全局安装，除非你明确使用 sudo 执行安装。\n用户目录安装 在两种情况下，pip install 会将包安装到用户级别的 site-packages 目录下。\n第一种情况是被动触发，当执行全局安装没有权限时，pip 会自动将包安装到用户级别的 site-packages，例如使用 macOS 系统自带的 Python 时：\n1 2 3 4 ❯ pip3 install pyfiglet Defaulting to user installation because normal site-packages is not writeable ... Successfully installed pyfiglet-1.0.3 全局目录不可写入，但安装还是成功了，实际上是将包安装到了用户目录。查看刚刚的安装包，可以知道用户目录的具体位置。\n1 2 3 4 5 6 7 8 9 10 11 ❯ pip3 show pyfiglet Name: pyfiglet Version: 1.0.3 Summary: Pure-python FIGlet implementation Home-page: https://github.com/pwaller/pyfiglet Author: Peter Waller (Thanks to Christopher Jones and Stefano Rivera) Author-email: p@pwaller.net License: MIT Location: /Users/haoliangma/Library/Python/3.9/lib/python/site-packages Requires: Required-by: 第二种情况是，通过 --user 参数，明确要求将包安装在自己的用户目录下。\n1 2 3 4 5 6 7 8 9 10 11 12 ❯ pip3 install --user pyfiglet ❯ pip3 show pyfiglet Name: pyfiglet Version: 1.0.3 Summary: Pure-python FIGlet implementation Home-page: https://github.com/pwaller/pyfiglet Author: Peter Waller (Thanks to Christopher Jones and Stefano Rivera) Author-email: p@pwaller.net License: MIT Location: /Users/haoliangma/.local/lib/python3.10/site-packages Requires: Required-by: 这次使用的是 pyenv 管理的 python，包被安装到用户的 .local/lib/python3.10/site-packages 目录中。\n我们还发现，不同方式安装的 Python，可能有不同的用户目录。不用安装包，可以执行python3 -m site --user-site 命令，获得当前 Python 的用户目录：\n1 2 3 4 5 6 7 # pyenv 管理的 python ❯ python3 -m site --user-site /Users/haoliangma/.local/lib/python3.10/site-packages # macOS 系统自带的 python ❯ python3 -m site --user-site /Users/haoliangma/Library/Python/3.9/lib/python/site-packages 虚拟环境安装 虚拟环境是为每个项目创建一个独立的，与其他项目隔离的“沙盒”。\n在已激活 (activated) 的虚拟环境中执行 pip install，会将包安装到虚拟环境的 site-packages 目录下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 在项目目录下创建一个名为 .venv 的虚拟环境 ❯ python3 -m venv .venv # 激活它 (macOS/Linux) ❯ source .venv/bin/activate # 安装包 (.venv) ❯ pip3 install pyfiglet # 查看包的安装位置 (.venv) ❯ pip3 show pyfiglet Name: pyfiglet Version: 1.0.3 ... Location: /Users/haoliangma/works/demo/.venv/lib/python3.10/site-packages ... Location 清晰地指向了我们刚刚创建的 .venv 目录内部，与全局或用户目录的路径毫无关系。\n在激活虚拟环境的状态下，我们再次运行之前的查询命令，查看当前的 site-packages 路径：\n1 2 (.venv) ❯ python3 -c \u0026#34;import site; print(site.getsitepackages())\u0026#34; [\u0026#39;/Users/haoliangma/works/demo/.venv/lib/python3.10/site-packages\u0026#39;] 查看与管理已安装的包 pip list pip list 会列出当前 Python 环境中所有已安装的包及其版本号。\n使用 pyenv 管理的 python，在全局环境中运行pip list，会列出全局和用户目录下的包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ❯ pip3 list Package Version ---------- ------- pip 23.0.1 pyfiglet 1.0.3 setuptools 65.5.0 ❯ pip3 show pyfiglet Name: pyfiglet Version: 1.0.3 Summary: Pure-python FIGlet implementation Home-page: https://github.com/pwaller/pyfiglet Author: Peter Waller (Thanks to Christopher Jones and Stefano Rivera) Author-email: p@pwaller.net License: MIT Location: /Users/haoliangma/.local/lib/python3.10/site-packages Requires: Required-by: 从这里可以，pip list 中列出的pyfiglet，是安装在用户目录的 site-packages 中。\n查看 macOS 系统自带的 Python 安装了哪些包：\n1 2 3 4 5 6 7 8 9 10 11 ❯ pip3 list Package Version ------------ -------- altgraph 0.17.2 future 0.18.2 macholib 1.15.2 pip 21.2.4 setuptools 58.0.4 six 1.15.0 vboxapi 1.0 wheel 0.37.0 这里的列表通常会长很多，因为它包含了很多操作系统或开发工具（如 Xcode）正常运行所依赖的包。\n在一个全新的、刚刚激活的虚拟环境中执行 pip list：\n1 2 3 4 5 ❯ pip3 list Package Version ---------- ------- pip 23.0.1 setuptools 65.5.0 pip freeze pip list 非常适合日常查看，但当我们需要将项目依赖分享给他人或进行部署时，pip freeze 命令是更好的选择。\npip freeze 的输出格式与 pip list 类似，但它遵循一种特定的格式，可以直接用于依赖文件。\n1 ❯ pip freeze \u0026gt; requirements.txt pip install 使用依赖文件重建环境：\n1 2 3 $ python3 -m venv .venv $ source .venv/bin/activate (.venv) $ pip install -r requirements.txt 总结 本文从一个常见的认知误区出发，首先明确了 pip 本身是依赖于 python 解释器运行的一个包。\n随后，我们深入探讨了在复杂的开发环境中，如何使用命令，定位当前正在使用的 python 与 pip 的真实位置，详细解析了 pip install 的三大目的地：全局、用户目录和虚拟环境。\n为了方便回顾和查阅，以下是本文提到的所有核心命令及其功能摘要：\n功能分类 命令 描述 定位与识别 which \u0026lt;command\u0026gt; (macOS/Linux) 在 PATH 环境变量中查找并显示命令的可执行文件路径。 where \u0026lt;command\u0026gt; (Windows) 功能与 which 类似，在 PATH 中查找命令的路径。 python3 -c \u0026quot;import sys; print(sys.executable)\u0026quot; 精准查找并打印当前正在运行的 Python 解释器的绝对路径，不受 shims 等影响。 pip3 --version 显示 pip 的版本号及其所属的 Python 环境和具体的 site-packages 路径。 pip3 show \u0026lt;package\u0026gt; 显示指定包的详细信息，尤其是其 Location 字段，是确认包安装位置的关键命令。 python3 -c \u0026quot;import site; print(site.getsitepackages())\u0026quot; 显示当前 Python 环境的 site-packages 目录列表。 python3 -m site --user-site 显示当前 Python 环境的用户专属 site-packages 目录路径。 包管理 pip3 install \u0026lt;package\u0026gt; 安装一个 Python 包。默认尝试全局安装，无权限时可能自动转为用户目录安装。 pip3 install --user \u0026lt;package\u0026gt; 明确指定将包安装到用户 site-packages 目录。 pip3 install -r requirements.txt 从指定的 requirements.txt 文件中读取并安装所有依赖包，用于环境复现。 pip3 list 列出当前环境中所有已安装的包及其版本，适合日常查看。 pip3 freeze \u0026gt; requirements.txt 将 pip freeze 的输出重定向，生成或覆盖 requirements.txt 依赖清单文件。 ","date":"2025-07-20T08:05:26+08:00","permalink":"https://mahaoliang.tech/p/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-python-%E4%B8%8E-pip/","title":"深入理解 Python 与 pip"},{"content":"对于许多 Python 开发者而言，venv、pyenv 与 conda 如同三位熟悉的“魔术师”。我们熟练地使用它们的命令来隔离项目、切换版本，却常常对其背后的运作一知半解。\n本文的目标，正是要揭开这些工具的魔法外衣。我们不罗列命令，而是直击核心：深入 PATH 环境变量、Shim 机制和文件系统布局，揭示它们各自的实现原理。理解了底层，你才能真正驾驭它们，告别环境管理的混乱。\n争夺 PATH 环境变量 Python 环境管理工具的核心机制，都围绕着对 PATH 环境变量的控制。\nPATH 是一个由目录路径组成的有序列表。当你执行一个命令时，操作系统会按照这份列表的顺序，从左到右依次在这些目录中查找对应的可执行文件。一旦找到，便立即执行并停止搜索。\nvenv、conda 和 pyenv 都通过修改 PATH 来确保其管理的 Python 解释器被优先调用，但它们实现这一目标的具体策略存在不同。\n直接修改 PATH：venv 与 conda 的策略 venv 和 conda 采用的是一种直接修改 PATH 变量的策略。当一个环境被激活时，该环境的 bin 目录（在 Windows 上是 Scripts 目录）会被插入到 PATH 列表的最前端。\nvenv 的实现 执行 source .venv/bin/activate 命令后，该脚本会获取当前 PATH 变量的值，并将 /path/to/project/.venv/bin 这个路径字符串添加到其最左侧。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 查看当前的 PATH 变量（为清晰起见，已简化） $ echo $PATH /usr/local/bin:/usr/bin:/bin # 查找 python 命令的位置 $ which python3 /usr/bin/python3 # 激活虚拟环境 $ source .venv/bin/activate # 再次查看 PATH 变量 $ echo $PATH /path/to/project/.venv/bin:/usr/local/bin:/usr/bin:/bin # 再次查找 python 命令的位置 $ which python3 /path/to/project/.venv/bin/python3 conda 的实现： conda activate my-env 命令执行的逻辑与 venv 相同。它会将 /path/to/miniconda3/envs/my-env/bin 目录路径插入到 PATH 变量的最前端。\n这种策略的共同点是：激活操作直接将包含目标 Python 解释器的目录置于最高查找优先级。\n通过 Shim 间接控制：pyenv 的策略 pyenv 采用了一种更为间接的控制策略。它不直接将任何特定版本的 Python bin 目录添加到 PATH，而是在 pyenv 初始化时，要求用户将一个名为 shims 的特殊目录添加到 PATH 的最前端。\npyenv 初始化后的 PATH\n1 2 $ echo $PATH /Users/haoliangma/.pyenv/shims:/opt/homebrew/bin:... shims 目录是 pyenv 实现版本动态切换的关键。该目录中包含了一系列与常用命令（如 python, pip）同名的可执行文件，这些文件被称为 Shim。\n当用户执行 python 命令时，实际运行的是 ~/.pyenv/shims/python 这个 Shim 文件。该文件的核心任务是：\n执行 pyenv 的内部逻辑。 pyenv 根据当前配置（如 .python-version 文件、全局设置或环境变量）确定需要使用的真实 Python 版本（例如 3.10.9）。 pyenv 随后将命令的执行权转发给该版本的真实解释器，其路径为 ~/.pyenv/versions/3.10.9/bin/python。 这种策略的特点是：PATH 的最高优先级被一个固定的 Shim 目录占据，由该目录中的程序根据上下文动态地决定并调用真正的目标可执行文件。\n本章小结 venv 和 conda 通过直接修改 PATH 将特定环境的 bin 目录置于首位，是一种静态的状态切换。而 pyenv 则是通过一个固定的 shims 目录来拦截命令，并进行动态的命令转发。\n为什么 pyenv + venv 可以合作 既然 pyenv 和 venv 都会争夺 PATH 环境变量的最高优先级，为什么它们的组合不会产生冲突呢？\n答案在于，它们对 PATH 的控制服务于一个有序的、分阶段的执行流程，并通过 符号链接（Symbolic Link） 这一关键技术，确保了执行权的无缝交接。\n阶段一：环境构建 (pyenv Shim 机制主导) 在创建虚拟环境的阶段，pyenv 的 Shim 机制起着决定性作用，它确保了 venv 模块由正确版本的 Python 解释器执行。\n初始状态 pyenv 已初始化，~/.pyenv/shims 目录位于 PATH 的最前端。用户已通过 pyenv shell 3.10.9 等命令指定了 Python 版本。\n执行创建虚拟环境的命令 1 $ python -m venv .venv 命令的执行解析 Shell 依据 PATH 顺序，首先执行 ~/.pyenv/shims/python 这个代理脚本。\npyenv 的 Shim 逻辑被触发，它检测到版本配置 (.python-version)，确定目标为 3.10.9 版本。\npyenv 随即将执行权转发给真实的解释器：~/.pyenv/versions/3.10.9/bin/python。\n最终，由 3.10.9 版本的解释器来执行 -m venv .venv 任务。\nvenv 的核心产出 在 .venv/bin/ 目录下，venv 模块创建了一个名为 python 的符号链接。此链接的目标地址，被精确地设置为用于创建它的那个解释器的绝对路径。\n1 2 $ ls -l .venv/bin/python3 lrwxr-xr-x 1 haoliangma staff 52B 7 20 13:21 .venv/bin/python3 -\u0026gt; /Users/haoliangma/.pyenv/versions/3.10.9/bin/python3 这个符号链接的存在至关重要，它以文件系统级别的指针形式，永久性地记录了该虚拟环境所绑定的 Python 解释器版本。至此，pyenv 在构建阶段的任务已经完成。\n阶段二：环境激活 (venv 接管 PATH 优先级) 在环境被激活后，venv 虽然在 PATH 层面取得了最高优先级，但符号链接机制确保了最终的执行流依然正确。\n激活虚拟环境 1 $ source .venv/bin/activate PATH 的变更 activate 脚本将 .venv/bin 目录插入到 PATH 的最前端，此时 PATH 变为：\n1 2 $ echo $PATH /path/to/project/.venv/bin: /Users/haoliangma/.pyenv/shims:... 从 PATH 的顺序上看，.venv/bin 的优先级已经高于 pyenv 的 shims 目录。\n最终命令的执行解析 当用户再次输入 python3 命令：\nShell 首先在 PATH 的第一站 /path/to/project/.venv/bin 中找到了 python3 文件。\n操作系统识别出这是一个符号链接。\n操作系统自动解引用（dereference）该链接，即跟随指针找到了它的真实目标：/Users/haoliangma/.pyenv/versions/3.10.9/bin/python3。\n最终，由 pyenv 管理的 3.10.9 解释器被执行。\n本章小结 pyenv 和 venv 的 PATH 争夺之所以没有导致冲突，是因为它们的交互是一个非竞争性的时序过程：\n在环境创建时，pyenv 的 Shim 机制处于活动状态，用于选择正确的 Python 解释器。\nvenv 将这个选择结果通过符号链接的形式固化下来。\n在环境激活后，venv 接管 PATH 的最高优先级。此时 pyenv 的 Shim 机制虽然被绕过，但这无关紧要，因为符号链接已经确保了任何对 python 的调用都会被直接路由到 pyenv 事先选定的那个解释器。\n为什么 pyenv 与 conda 会冲突 两套并行的版本管理体系 pyenv 与 conda 之间的冲突，首要根源在于，两者都试图控制 Python 解释器的版本管理。\npyenv 的功能：其核心功能是安装和管理多个不同版本的 Python 解释器（例如 3.9.13, 3.10.9），并将它们存储在 ~/.pyenv/versions/ 目录下。\nconda 的功能：conda 将 Python 解释器本身也视为一个普通的软件包。执行 conda create -n myenv python=3.9 时，conda 会从其官方渠道下载一个预编译的 Python 3.9，并将其安装在 ~/miniconda3/envs/myenv/ 目录内。\n这就造成了一个直接的矛盾：一个系统内存在两套独立的、用于获取和管理 Python 版本的机制。它们各自维护着不同的 Python 安装路径。\nPATH 控制权的互斥冲突 这是导致两者无法共存的最直接的技术原因。\npyenv 有效的前提是，~/.pyenv/shims 目录必须位于 PATH 环境变量的最前端。只有这样，pyenv 的代理脚本才能生效。\n而 conda 的激活操作，恰恰会破坏了这个前提。\n初始状态 假设 pyenv 和 conda 均已在 Shell 配置文件中初始化。PATH 的起始部分可能如下（取决于初始化顺序）：\n1 2 $ echo $PATH /home/user/.pyenv/shims:/path/to/miniconda3/condabin:... 激活虚拟环境 1 $ conda activate my-env conda 的 PATH 修改 conda activate 命令会强制将 my-env 环境的 bin 目录插入到 PATH 的最前端。\n冲突后的 PATH 状态 PATH 变量变为：\n1 2 $ echo $PATH /path/to/miniconda3/envs/my-env/bin:/home/user/.pyenv/shims:... 现在，conda 环境的 bin 目录取代了 pyenv 的 shims 目录，成为了 PATH 的最高优先级。\n最终的执行解析 当用户再次输入 python 命令时，Shell 首先在 /path/to/miniconda3/envs/my-env/bin 目录中找到了 python 可执行文件。这个文件是 conda 自己安装的，与 pyenv 毫无关系。pyenv 的 shims 目录因为排在后面，其中的代理脚本根本没有机会被执行。\n与 pyenv+venv 的组合不同，这里不存在任何“交接”机制。conda 环境中的 python 不是一个指向 pyenv 所管理版本的符号链接；它是一个由 conda 独立安装的、完全自洽的二进制文件。\n本章小结 在 PATH 控制上，pyenv 要求其 shims 目录占据最高优先级以实现动态代理，而 conda activate 则要求其环境 bin 目录在激活期间占据最高优先级。\n这两个要求是互斥的，因此，两者无法稳定共存。\n隔离空间，本地分散 vs. 全局集中 在解决了“如何激活”的问题后，我们下一个要探究的是：这些隔离的环境和它们所依赖的包，究竟被存放在了哪里？\n尽管 venv 和 conda 都为项目提供了独立的包安装空间，但它们在物理存储上采用了截然不同的策略。\nvenv：环境与项目同在 venv 遵循的是一种本地化、分散式的管理哲学。当你站在一个项目目录下，执行 python -m venv .venv 时，它会在当前目录下创建一个名为 .venv 的文件夹。这个文件夹就是你的整个虚拟环境。\n.venv 是一个自包含的目录，里面有独立的 bin（或 Scripts）和 lib 文件夹。当你在这个环境中 pip install requests 时，requests 库的所有文件都会被原封不动地放进 .venv/lib/pythonX.X/site-packages/ 目录下。\n这种范式的优缺点十分鲜明。\n优点\n概念清晰：环境与项目代码紧密绑定，一目了然。\n管理简单：当项目结束时，只需将整个项目文件夹删除，与之关联的虚拟环境也被一并彻底清理，不留任何痕迹。\n缺点\n空间冗余：这是它最大的弊端。如果你有十个 Web 项目都依赖于 Django 和 requests，那么你的硬盘上就会躺着十份几乎完全相同的库文件拷贝，造成了不小的磁盘空间浪费。 venv 的设计就像是为每个项目都配备了一个独立的“随身工具箱”，方便携带，但如果每个工具箱里的工具都大同小异，那无疑是种累赘。\nconda：统一管理与高效复用 与 venv 不同，conda 采用的是一种高度集中、统一管理的模式。它的存储体系主要由两个核心目录构成，通常位于你的用户主目录下（如 ~/miniconda3）：\nenvs 目录：所有通过 conda create 创建的环境，都以子目录的形式集中存放在这里。\npkgs 目录：这是 Conda 的“中央包仓库缓存”。所有下载过的包（包括不同版本的 Python 解释器本身）都会在这里存放一份。\n当你在 myenv 环境中安装 numpy 时，Conda 并不会将 numpy 的文件从 pkgs 目录完整地复制到 envs/myenv 目录下。相反，它会使用一种名为“硬链接”的文件系统特性。\n这种“中央集权”范式的优缺点也同样突出。\n优点\n空间优化：得益于硬链接，即使一百个环境都使用 numpy，它在物理磁盘上也只占用一份空间，极大地节省了资源。\n全局管理便利：只需一个 conda env list 命令，就能清晰地列出并管理本机上所有的 Conda 环境。\n缺点\n物理分离：环境与项目代码在文件系统上是分离的。这要求开发者需要自行维护“哪个项目对应哪个环境”的映射关系，有时可能会造成混淆。 conda 的设计更像一个大型的“中央仓库”，所有项目都按需从中领取工具的使用权，而不是复制一份。这种模式在处理拥有大量共同依赖的多个项目时，效率和优势尽显。\n总结 走过这趟深入 Python 环境管理底层的旅程，我们拨开了 venv、pyenv 与 conda 这三位“魔术师”的神秘面纱。理解了这些原理，可以让我们更好地管理 Python 环境，并更高效地使用 Python。\n我们花费精力去理解工具的内在，是为了在日常工作中能彻底忘掉它们的存在，将所有心力都投入到代码和创造本身。希望本文能帮助你找到那把最称手的钥匙，去打开更广阔的开发世界。\n","date":"2025-07-19T12:15:07+08:00","permalink":"https://mahaoliang.tech/p/%E6%8F%AD%E7%A7%98-python-%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","title":"揭秘 Python 环境管理的底层实现"},{"content":"前面我写文章分别介绍了 Python 的两个虚拟环境管理工具 venv 和 Conda ，并进行过适用场景对比。但具体应该如何选择呢，我想分享我个人的选择策略，希望能给你提供一个更具体的参考。\nmacOS 在 MacBook Pro 上，我一般进行纯 Python 开发，倾向于使用 pyenv + venv 的组合。pyenv 负责管理和切换全局的 Python 版本，venv 则为每个项目创建极致轻量的虚拟环境。\n这套组合非常优雅，工具链清晰解耦，完全符合这类项目的需求。\nWindows Windows 上的情况要复杂一些。\n在我的 Windows 笔记本 上，由于配备了 NVIDIA 显卡，可以用于 AI 和机器学习开发，所以会安装 miniconda，但一定要注意：\n不要“Add Miniconda3 to my PATH environment variable”，\n也不要“Register Miniconda3 as my default Python”，\n避免干扰系统。如果想使用 Conda，通过“开始菜单”找到并打开 Anaconda Prompt (Miniconda3) 来使用。\n至于使用哪种虚拟环境管理工具，需要根据场景选择。\n纯 Python 开发 纯 Python 开发，仍然使用 venv 创建虚拟环境。\nAI 开发 AI 开发，需要依赖复杂的 CUDA Toolkit 和 cuDNN。按道理应该使用 Conda，可以一键在虚拟环境中安装 CUDA Toolkit 和 cuDNN 本地依赖。\n1 conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 pytorch-cuda=12.4 -c pytorch -c nvidia 但最新的 pytorch 安装向导 Start Locally，已经取消了 Conda 选项，只能在 Previous PyTorch Versions 中找到 Conda 的安装命令。\nPyTorch 官方在 2024 年 10 月 22 日通过 GitHub Issue 正式宣布了这一重要决定：\n\u0026ldquo;2.5 will be the last release of PyTorch that will be published to the pytorch channel on Anaconda.\u0026rdquo;\n至于原因，官方声明中提到，将维护资源集中在用户最常用的平台上，可以提供更好的支持和更优质的用户体验。\n那么如果想使用最新版的 pytorch，就不能使用 Conda 了。还是老老实实参考文档，在全局环境中安装并设置 CUDA Toolkit 和 cuDNN，然后使用 venv 创建虚拟环境，拷贝执行 Start Locally 提供命令，在虚拟环境中安装 PyTorch。\n多版本需求 如果你的项目依赖特定的 Python 版本，那么建议使用 Conda，为项目创建指定 Python 版本的虚拟环境。\n复杂的本地依赖 Conda 能够轻松处理那些依赖复杂底层库，它不仅仅管理 Python 包，它管理的是一个完整的、包含所有底层二进制依赖的软件栈。对于依赖复杂非 Python 组件的项目，Conda 很适合。\n","date":"2025-07-17T10:37:55+08:00","permalink":"https://mahaoliang.tech/p/python-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E9%80%89%E6%8B%A9%E5%BB%BA%E8%AE%AE/","title":"Python 虚拟环境管理工具选择建议"},{"content":"为什么需要环境管理？ “在我电脑上明明能跑啊！”\n这句经典的抱怨背后，是无数开发者都曾遭遇的“依赖地狱”：项目 A 需要 TensorFlow 1.x，新项目 B 却要 TensorFlow 2.x；团队成员间的环境难以统一；系统自带的 Python 环境被各种库弄得一团糟。\n解决这一切的关键在于环境隔离：为每个项目创建一个独立的、干净的“沙盒”。而 Conda，正是实现这一目标的利器。\n本文将是一份全面的 Conda 指南，带你从核心用法、工作原理到最佳实践，让你彻底告别环境管理的混乱，拥抱一个更专业、高效的开发工作流。\nConda 是什么？ 很多初学者会将 Conda 简单地等同于一个虚拟环境工具，就像 Python 自带的 venv。这其实只说对了一半。要真正理解 Conda，你需要认识它的三重身份：\n环境管理器 (Environment Manager) 这是 Conda 最广为人知的功能。它允许你创建相互隔离的独立环境。每个环境都可以拥有自己专属的 Python 版本和一套独立的软件包。\n你可以为项目 A 创建一个搭载 Python 3.7 和旧版库的环境。 同时为项目 B 创建另一个搭载 Python 3.10 和最新库的环境。 这两个环境井水不犯河水，你可以通过一条简单的命令在它们之间自由切换。\n包管理器 (Package Manager) 这是 Conda 与 venv + pip 组合的一个区别：pip 是 Python 官方的包管理器，它主要从 PyPI (Python Package Index) 下载软件包；而 Conda 拥有自己独立的包管理系统和软件源（Channels）。\n它的关键优势在于：\n跨语言支持： Conda 不仅仅能安装 Python 包！它可以安装和管理任何语言的软件包，比如 C/C++ 库、R 语言包、CUDA 工具链、MKL 数学库等。这对于数据科学和机器学习领域至关重要，因为许多高性能计算库（如 NumPy, TensorFlow）的底层都依赖于这些非 Python 组件。Conda 会一并帮你处理好这些复杂的依赖关系。\n二进制分发： pip 有时会下载源码包，需要在你的本地机器上进行编译，这个过程可能因为缺少编译器或依赖库而失败。而 Conda 官方渠道中的包绝大多数都是预先编译好的二进制文件，针对你的操作系统（Windows, macOS, Linux）量身打造。这意味着 conda install 通常比 pip install 更快、更稳定，极大地避免了烦人的编译错误。\n发行版管理器 (Distribution Manager) 这一点常常被忽视。Conda 能够将 Python 解释器本身也视作一个普通的软件包来管理。当你执行 conda create -n myenv python=3.9 时，Conda 不会去寻找你系统上已有的 Python，而是会从自己的软件源中下载一个纯净、独立的 Python 3.9 解释器，并安装到 myenv 这个环境中。\n这意味着，你无需借助 pyenv 这类工具，只用 Conda 就能在同一台机器上轻松拥有和管理 Python 3.7, 3.8, 3.9\u0026hellip; 等任意多个版本，并将它们分配给不同的项目环境。\n总结一下： venv 只负责创建隔离的环境“空壳”，包的安装和管理仍由 pip 负责，且它无法管理 Python 版本。而 Conda 则是一个集环境隔离、包安装、依赖处理、Python 版本管理于一身的“全能瑞士军刀”。\n下载和安装 Anaconda vs. Miniconda 在安装 Conda 时，你通常会遇到两个选项：Anaconda 和 Miniconda。这常常让新手感到困惑。\n可以这样理解：\nAnaconda： 这是一个“精装修豪华套餐”。它不仅包含了核心的 Conda 工具，还预装了一个特定版本的 Python 和超过 150 个常用的科学计算、数据分析包，如 NumPy, Pandas, Scipy, Jupyter Notebook 等。它的安装包体积较大（通常几百 MB 到数 GB），旨在提供“开箱即用”的体验。\nMiniconda： 这是一个“毛坯房”。它只包含了最核心的 Conda 工具和一个基础的 Python 解释器。整个安装包非常小巧（几十 MB）。安装完成后，你的环境是几乎纯净的，里面没有任何多余的包。你需要什么，就通过 conda install 自己动手安装什么。\n我的建议是：\n对于所有开发者，尤其是追求环境纯净和良好习惯的开发者，我们强烈推荐从 Miniconda 开始。\n安装 Miniconda 后，你就拥有了完整的 Conda 功能。需要用到 Anaconda 里的那些包？没问题，只需创建一个新环境，然后用 conda install numpy pandas jupyter 一行命令就能搞定，效果完全一样。\n下载 Miniconda 准备好开始了吗？让我们一起动手安装 Miniconda。\n访问 anaconda 的官方下载页面https://www.anaconda.com/download，点击跳过注册，进入正式下载页面。\n在页面右侧“Miniconda Installers”的下方，根据你的操作系统和芯片架构，选择最新的安装包。\n安装 Miniconda Windows 用户 双击下载的 .exe 文件。 在 \u0026ldquo;Installation Type\u0026rdquo; 步骤，推荐选择 “Just Me”，这可以避免很多权限问题。 关键步骤： 安装程序会提供两个高级选项，请按照推荐设置： 不勾选 \u0026ldquo;Add Miniconda3 to my PATH environment variable\u0026rdquo; (将 Miniconda 添加到系统 PATH)。官方不推荐这样做，因为它可能干扰系统上其他的软件。我们应当使用 Conda 自己的方式来激活环境。 不勾选 \u0026ldquo;Register Miniconda3 as my default Python\u0026rdquo; (将 Miniconda 注册为默认 Python)。如果你希望系统默认的 Python 就是 Conda 的，可以勾选，但对于初学者，不勾选也无妨，保持系统纯净。 完成安装后，通过“开始菜单”找到并打开 Anaconda Prompt (Miniconda3) 来使用 Conda。 macOS / Linux 用户 打开你的终端 (Terminal)。 进入到你下载 .sh 文件的目录（通常是 Downloads 目录）。 运行安装脚本，命令如下（请将文件名替换为你下载的实际文件名）： 1 bash Miniconda3-latest-MacOSX-arm64.sh 安装过程中，按 Enter 查看许可协议，然后输入 yes 同意。 当询问安装位置时，直接按 Enter 接受默认路径即可（通常是 ~/miniconda3）。 关键步骤： 安装的最后，它会询问 Do you wish to update your shell profile to automatically initialize conda?。务必输入 yes。这一步会自动修改你的 shell 配置文件（如 .bashrc 或 .zshrc），让 conda 命令在你的命令行终端中可用。 完成安装后，请务必关闭并重新打开你的终端窗口（或 Anaconda Prompt）。这是为了让刚才的 conda init 配置生效。\n然后，输入以下命令：\n1 conda --version 如果安装成功，它会显示出 Conda 的版本号，例如 conda 25.5.1。你可能还会注意到，命令行提示符的前面多了一个 (base) 的字样。这表示你当前正处于 Conda 的 base 环境中。\n恭喜你，Conda 已经成功安装并准备就绪！接下来，我们将学习如何驾驭它。\nConda 核心命令实战 Conda 的强大之处在于其简洁而强大的命令行接口。掌握下面这些核心命令，你就足以应对 95% 以上的日常开发需求。\n打开你的终端（macOS/Linux）或 Anaconda Prompt (Windows)，让我们开始施展魔法。\n环境管理 (Environment Management) 环境管理是 Conda 的基石。请记住：不要在 base 环境中工作，为每个项目创建新环境。\n创建新环境 假设我们要启动一个名为 data_analysis 的新项目，并且希望使用 Python 3.10.18。\n1 2 # 语法: conda create --name \u0026lt;环境名\u0026gt; python=\u0026lt;python版本\u0026gt; [其他包...] conda create --name data_analysis python=3.10.18 Conda 会解析依赖，下载一个独立的 Python 3.10.18 和一些基础包，然后为你创建一个名为 data_analysis 的环境。你还可以在创建时就指定要安装的包：\n1 2 # 创建环境的同时安装 pandas 和 matplotlib conda create -n data_analysis python=3.10.18 pandas matplotlib 注意，参数 --name 可以缩写为 -n。\n查看可安装的 Python 版本 在创建环境时，你可能会问：“我怎么知道哪些 Python 版本是可用的呢？”Conda 把 Python 也当作一个包来管理，所以我们可以用 search 命令来查找：\n1 conda search python 这个命令会列出 Conda 软件源中所有可供安装的 Python 版本。这样，在执行 conda create 之前，你就可以清楚地知道有哪些版本可以选择。\n激活（进入）环境 环境创建好后，它就像一个独立的房间，使用 activate 命令进入它：\n1 conda activate data_analysis 执行后，你会发现命令行提示符的前缀从 (base) 变成了 (data_analysis)。这明确地告诉你：你现在就在 data_analysis 这个沙盒里了！ 在此之后，你所有关于 python、pip、conda install 的操作，都将只影响这个环境。\n停用（退出）环境 项目工作完成后，或者需要切换到其他项目时，使用 deactivate 命令退出当前环境，返回到 base 环境。\n1 conda deactivate 执行后，提示符前面的 (data_analysis) 就会消失，变回 (base)。\n列出所有环境 想看看自己都创建了哪些独立环境？\n1 2 conda env list # 或者 conda info --envs 这个命令会列出所有已创建的环境，并在当前激活的环境旁边用星号 * 标记。\n删除环境 当一个项目彻底结束，不再需要对应的环境时，可以将其彻底删除以释放磁盘空间。\n1 2 3 # 确保你已退出该环境 (conda deactivate) # 语法：conda remove --name \u0026lt;环境名\u0026gt; --all conda remove -n data_analysis --all --all 参数至关重要，它会删除环境下的所有包以及环境本身。\n包管理 (Package Management) 进入了指定的环境后，接下来就是为项目“添砖加瓦”——安装所需要的各种库。\n安装包 在已激活的环境中，使用 conda install 命令。\n1 2 3 4 5 6 7 8 9 10 11 # 激活环境 conda activate data_analysis # 安装单个包 conda install scikit-learn # 同时安装多个包 conda install beautifulsoup4 requests # 安装指定版本的包 conda install tensorflow=2.10.0 查看已安装的包 1 2 # 必须在激活的环境中执行 conda list 上面的命令会列出当前环境中所有的包及其版本号。\n搜索可用的包 不确定某个包是否存在，或者想看看有哪些可用的版本？\n1 conda search numpy 这个命令会搜索所有名为 numpy 的包及其可用版本。\n更新包 1 2 3 4 5 # 更新单个包到最新兼容版本 conda update pandas # 更新环境中的所有包 conda update --all 删除包 1 2 # 从当前环境中删除一个包 conda remove beautifulsoup4 环境复现 这是 Conda 最强大的功能之一，也是保证团队协作一致性的关键。我们可以将一个环境的所有配置导出到一个文件中，其他人拿到这个文件就能一键复制出完全相同的环境。\n导出环境配置 首先，激活你想要导出的环境，然后执行：\n1 2 conda activate data_analysis conda env export \u0026gt; environment.yml 这会生成一个名为 environment.yml 的文件。打开它看看，里面精确记录了环境名称、所有包的版本号。\n从文件创建环境 当你的同事拿到这个 environment.yml 文件后，只需一行命令，就能在自己的机器上克隆出一个一模一样的环境：\n1 2 # 无需先创建环境，Conda 会根据文件中的名字自动创建 conda env create -f environment.yml 核心命令总结 功能分类 常用命令 说明 环境管理 conda create -n myenv python=3.10.18 创建一个名为 myenv 的新环境，并指定 Python 版本。 conda activate myenv 激活（进入）指定的环境。 conda deactivate 停用（退出）当前环境，返回 base 环境。 conda env list 列出所有已创建的环境。 conda remove -n myenv --all 彻底删除一个环境及其所有内容。 包管理 conda install \u0026lt;package_name\u0026gt; 在当前激活的环境中安装一个或多个包。 conda list 查看当前激活环境中已安装的所有包。 conda update \u0026lt;package_name\u0026gt; 更新指定的包。 conda remove \u0026lt;package_name\u0026gt; 从当前激活的环境中移除一个包。 环境复现 conda env export \u0026gt; environment.yml 将当前激活环境的配置导出到 environment.yml 文件。 conda env create -f environment.yml 根据 environment.yml 文件创建或复现一个完整的环境。 信息查询 conda --version 查看 Conda 的版本号。 conda search python 列出 Conda 源中所有可供安装的 Python 版本。 conda search \u0026lt;package_name\u0026gt; 在软件源中搜索一个包的所有可用版本。 深入原理：Conda 是如何工作的？ 我们已经学会了 Conda 的核心命令，能够熟练地创建、切换和管理环境。但是，你是否好奇过：\n当执行 conda install numpy 时，这个包到底被安装到哪儿去了？ conda activate myenv 这条命令，是如何让 python 指向一个全新的解释器？ Conda 会不会搞乱系统自带的 Python 环境呢？ 让我们一起深入 Conda 的“后台”，一探究竟。\n依赖安装到哪里了？ 当安装 Miniconda 后，它会在你的用户主目录下创建一个文件夹：macOS 上默认是~/miniconda3，Windows 上默认是 C:\\Users\\\u0026lt;用户名\u0026gt;\\miniconda3。这个文件夹就是 Conda 的大本营，其中有两个子目录至关重要：envs 和 pkgs。\nenvs 目录：环境的独立“公寓” envs 目录是所有虚拟环境的家。当你执行 conda create -n data_analysis 时，Conda 会在 envs 目录下创建一个名为 data_analysis 的子文件夹。\n这个 data_analysis 文件夹不是一个空壳，而是一个几近完整的、独立的 Python 环境。它里面包含了：\n一个独立的 Python 解释器 (envs/data_analysis/bin/python) 独立的包安装目录 (envs/data_analysis/lib/pythonX.X/site-packages) 所有安装到这个环境的包的二进制文件和脚本 (envs/data_analysis/bin/) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ❯ tree -L 3 ~/miniconda3/envs /Users/haoliangma/miniconda3/envs └── data_analysis ├── bin │ ├── ... │ ├── python -\u0026gt; python3.10 │ ├── python3 -\u0026gt; python3.10 │ ├── python3.1 -\u0026gt; python3.10 │ ├── python3.10 │ └── ... ├── ... ├── lib │ ├── ... │ ├── python3.10 │ │ ├── site-packages │ │ │── ... │ │ └── ... │ └── ... └── ... 每个环境都是一个独立的目录，这就是 Conda 实现文件级别隔离的基础。删除环境时，只需删掉 envs 下对应的文件夹即可，干净利落。\npkgs 目录：包的中央仓库 这个目录存储所有下载的包文件缓存。Conda 会将下载的包保存在这里，以便在创建或更新环境时可以快速访问，而无需重新下载。\n如何做到隔离的？ 文件隔离解决了存储问题，但运行时隔离又是如何实现的呢？为什么在激活 data_analysis 后，我在终端里输入 python，系统就知道要运行 ~/miniconda3/envs/data_analysis/bin/python，而不是系统自带的 /usr/bin/python？\n答案在于一个至关重要的环境变量：PATH。\nPATH 变量是一系列由冒号（在 Windows 上是分号）隔开的目录路径。当你在终端输入一个命令（如 python、pip）时，操作系统会按照 PATH 变量中列出的顺序，从左到右依次在这些目录里查找是否存在同名的可执行文件。一旦找到，就立即执行，并停止向后搜索。\nconda activate data_analysis 命令的核心魔法就在于：\n它会暂时性地修改当前终端会话的 PATH 变量，将当前激活环境的 bin 目录路径（例如 ~/miniconda3/envs/data_analysis/bin）添加到 PATH 变量的最前面。\n让我们看一个例子：\n激活前，查看 PATH 环境变量： 1 2 $ echo $PATH /Users/haoliangma/miniconda3/bin:... 执行 conda activate data_analysis 之后，查看 PATH 环境变量： 1 2 3 $ conda activate data_analysis $ echo $PATH /Users/haoliangma/miniconda3/envs/data_analysis/bin:... 现在，当你输入 python，操作系统会首先在 ~/miniconda3/envs/data_analysis/bin 目录里查找。找到了，它立刻执行这个文件，搜索结束。\n系统自带的 /usr/bin/python 因为排在后面，根本没有机会被找到。这就实现了运行时的完美隔离。\n而 conda deactivate 命令则执行相反的操作：它会从 PATH 变量中移除之前添加的路径，将其恢复到激活前的状态。\nConda 会影响系统环境吗？ 设计上，Conda 不会“污染”你的系统环境。\nConda 所有的环境和包都严格限制在 Miniconda 的安装目录内。conda activate 对 PATH 的修改也仅限于当前的终端会话，一旦关闭窗口，一切都会复原。它不会去修改或覆盖你系统目录（如 /usr/bin）下的任何文件。\n唯一的“例外”是 conda init 命令。\n在你安装 Miniconda 的最后一步，或者手动执行 conda init zsh 时，它会在你的 Shell 配置文件（~/.zshrc）的末尾添加一小段脚本。\n这一步是必要且安全的。 这段脚本的作用是让 conda activate 等命令能够正确地修改你当前 Shell 的环境变量。如果没有它，conda 命令本身可能可用，但 activate 这种需要与 Shell 交互的功能将无法工作。\n你可以随时打开你的 .bashrc 或 .zshrc 文件查看 Conda 添加的内容，它有清晰的注释 # \u0026gt;\u0026gt;\u0026gt; conda initialize \u0026gt;\u0026gt;\u0026gt;。如果你想彻底移除 Conda，除了删除 Miniconda 的安装目录，只需将这段脚本从配置文件中删除即可。\n横向对比，选择适合的工具 Conda 功能强大，但它并非唯一的环境管理工具。在 Python 的世界里，还有 venv 和 pyenv 等广受欢迎的工具，它们有各自不同的适用场景。\n理解它们之间的区别，能帮助你根据自己的项目需求，选择最合适的工具。\nConda vs. venv 这是最常见的比较。venv 是 Python 3.3+ 版本中内置的虚拟环境创建工具，它通常与 pip（Python 官方包安装器）配合使用，形成了一套轻量级的环境管理方案。\n让我们用一个表格来清晰地对比它们：\n特性 / 对比项 Conda venv + Pip 核心定位 一体化解决方案：环境、包、Python 版本全包 轻量级组合拳：venv 管环境，pip 管包 管理范围 语言无关：能管理 Python, R, C++, CUDA 等任何软件包。 专注 Python：只能管理 Python 包。 Python 版本管理 内置功能：可自行下载和管理任意版本的 Python 解释器。 不具备：使用创建环境时系统当前激活的 Python 版本。 包来源 Conda Channels (如 anaconda, conda-forge)，主要是预编译二进制包。 PyPI (Python Package Index)，包含源码包和 Wheels (二进制包)。 依赖解析能力 非常强大。Conda 在安装前会进行严格的依赖关系检查，能解决复杂的非 Python 依赖（如 MKL, cuDNN）。 相对较弱。Pip 的依赖解析器近年来有改进，但处理复杂或冲突的依赖时仍可能遇到困难。 跨平台一致性 极高。通过 environment.yml 文件，可以保证在 Windows, macOS, Linux 上复现几乎完全一致的环境。 较好，但有风险。requirements.txt 文件在不同操作系统间可能因系统级依赖不同而表现不一。 适用场景 数据科学、机器学习、生物信息学等需要复杂非 Python 依赖的项目；需要管理多 Python 版本的场景。 Web 开发 (Django, Flask)、纯 Python 库开发、简单脚本等依赖相对纯净的场景。 简单总结：\n选择 venv + pip，如果你：\n在做纯粹的 Python 项目，如 Web 开发。 项目的依赖项简单，不涉及复杂的 C/C++ 库。 选择 Conda，如果你：\n数据科学或科学计算领域，需要处理 NumPy, SciPy, TensorFlow 等依赖复杂底层库的包。 需要在一个项目中混合使用 Python 和其他语言的工具（如 R）。 希望一个工具就能搞定环境和 Python 版本的所有问题。 Conda vs. pyenv 另一个让初学者困惑的组合是 Conda 和 pyenv。两者似乎都能管理 Python 版本，它们有什么不同？\npyenv 是一个纯粹的 Python 版本管理器。它的目标只有一个：让你在系统上轻松安装、切换多个 Python 版本（例如，全局用 3.10，某个项目用 3.8）。它本身不管理虚拟环境。pyenv 需要和 venv 配合使用：用 pyenv 切换到项目的目标 Python 版本，然后用该版本下的 venv 模块创建项目专属的虚拟环境。\npyenv 通过一种名为 \u0026ldquo;shims\u0026rdquo; 的机制工作。它会在你的 PATH 路径最前面插入一个 ~/.pyenv/shims 目录。当你执行 python 命令时，实际运行的是 shims 里的一个脚本，这个脚本会根据你当前的配置（全局、项目局部等）决定启动哪个版本的真实 Python 解释器。\n如前所述，Conda 将 Python 解释器本身也视为一个普通的“包”。conda create -n data_analysis python=3.8 会为你下载并安装一个独立的 Python 3.8，它与系统中的其他 Python 绝缘。\n关键区别： pyenv 管理的是“裸露”的 Python 解释器，而 Conda 管理的是包含 Python 解释器的“环境”。\n强烈建议不要同时使用 Conda 和 pyenv 混用 Conda 和 pyenv 就像让两个不同的交通指挥员，在同一个十字路口同时指挥交通，结果必然是混乱和冲突。\n冲突的根源在于 PATH 的控制权之争：\npyenv 通过 shims 机制，劫持了 python 命令的调用。 Conda 通过 conda activate，修改 PATH 变量，也想控制 python 命令的指向。 当你同时安装并初始化了两者，执行 python 命令时，到底听谁的？这取决于你的 Shell 配置中，谁的初始化脚本排在后面，谁就可能覆盖前者的设置。这会导致一些极其诡异且难以排查的问题。\n如果你的工作流以数据科学为中心，或者你喜欢 Conda 的一体化便利性，那就只用 Conda。让它来管理你所有的环境和 Python 版本。\n如果你是一名 Python Web 开发者或库开发者，偏爱 UNIX-like 的小工具组合哲学，那么 pyenv + venv 是一个非常优雅和强大的组合。\n避免将两者混合，可以为你节省大量调试环境问题的时间，让你可以专注于代码本身。\n总结 回顾一下我们的收获，Conda 的核心价值：\n不仅仅是虚拟环境： 我们了解到，Conda 是一个集环境管理、包管理、Python 版本管理于一身的“三合一”强大工具。它通过在 envs 目录中创建隔离的文件系统，并在 pkgs 目录中共享缓存，实现了高效、节省空间的隔离。\n强大的依赖处理： 凭借其跨语言的包管理能力和预编译的二进制包，Conda 能够轻松处理那些依赖复杂底层库（如 C++, FORTRAN, CUDA）的科学计算包，这是它在数据科学领域封神的关键。\n我们对比了 Conda 与 venv/pip 和 pyenv 的区别，结论是：没有最好的工具，只有最适合你当前场景的工具。\n","date":"2025-07-15T17:24:32+08:00","permalink":"https://mahaoliang.tech/p/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82-python-%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E7%A5%9E%E5%99%A8-conda/","title":"一文彻底搞懂 Python 环境管理神器 Conda"},{"content":"对于许多在 macOS 上工作的开发者来说，VMware Fusion 就像一把瑞士军刀，让我们能随时拥有一个纯净、独立的 Linux 环境。无论是进行 Linux 系统编程、用 Python 做 Linux 系统工具开发，还是部署和测试应用程序，虚拟机都为我们提供了一个完美的沙盒。\n然而，当你将所有的代码、项目文件和配置文件都存放在 Linux 虚拟机中，万一哪天虚拟机意外崩溃、无法启动，所有的心血都可能付诸东流。\n好消息是，VMware Fusion 提供了一个极其强大的功能，“共享文件夹”（Shared Folders），通过简单的配置，我们可以将 macOS 上的任意一个文件夹，直接“挂载”到 Linux 虚拟机的系统中，让它看起来就像是 Linux 自己的一个目录。\n这意味着，你可以在 macOS 或 Linux 上修改代码，因为它们都是同一份，同时你也可以使用 Time Machine 或其他云盘来实现代码的备份，即方便又安全。\n本文将作为你的向导，手把手带你完成从 VMware Fusion 的配置，到 Linux 系统配置的全部过程。让我们开始吧！\n准备工作，安装 VMware Tools 在开始配置共享之前，我们需要确保环境准备就绪，已经在 VMware Fusion 中安装好一个 Linux 发行版。\n接下来需要在 Linux 虚拟中安装 VMware Tools。\n你可以把 VMware Tools 理解为是连接 macOS 宿主机和 Linux 虚拟机的“桥梁”或“驱动程序”。像虚拟机屏幕分辨率自适应、鼠标无缝切换、剪贴板共享，以及我们本次的目标文件夹共享，都完全依赖于它。\n对于大多数的 Linux 发行版，官方和社区共同维护了一个开源实现，叫做 open-vm-tools，它已经预置在大多数 Linux 发行版的软件源中，安装起来非常方便。\nopen-vm-tools 主要由以下几个软件包组成：\nopen-vm-tools: 这是核心包，提供了最基础的功能，如虚拟机时钟同步、与宿主机的电源操作（正常关机）、心跳检测，以及最重要的，它包含了实现文件夹共享所必需的组件。\nopen-vm-tools-desktop: 它在核心包的基础上，增加了改善图形化交互体验的功能，例如剪贴板复制粘贴、窗口大小自适应等。\nopen-vm-tools-devel 和 open-vm-tools-debuginfo: 这两个包分别用于二次开发和调试，普通用户完全不需要关心。\n了解了这些，我们的目标就非常明确了。在虚拟机的命令行终端执行以下命令：\n1 2 3 4 5 6 # Ubuntu sudo apt update sudo apt install open-vm-tools # RHEL sudo yum install open-vm-tools 安装完成后，重启虚拟机，确保所有服务都能正常加载。下一步，我们就去 VMware Fusion 中开启文件共享功能。\n在 VMware Fusion 中配置共享 先将 Linux 虚拟机关机，然后进入虚拟机的设置面板，点击“共享”图标，勾选 “启用共享文件夹” 这个复选框，接着，点击下方的 + 号按钮，准备添加一个具体的共享目录。\n确保“启用”是勾选状态，并且权限设置为“读与写”，这样你才能在 Linux 中创建和修改文件。\n关闭配置，启动虚拟机，接下来需要在 Linux 中完成共享目录的挂载，就可以访问共享文件夹了。\n在 Linux 虚拟机中访问和挂载 在最新版的 open-vm-tools 的支持下，VMware 的共享文件夹通常会被自动挂载到一个系统级的公共目录：/mnt/hgfs (Host-Guest File System)。\n我们可以先验证一下。打开终端，运行：\n1 ls /mnt/hgfs 如果能看到你在上一步设置的共享名（如 linux），那么恭喜你，已经成功了！\n手工挂载 有时 /mnt/hgfs 目录是空的，这可能是因为权限或 FUSE 服务问题。解决方法是使用 vmhgfs-fuse 命令手动挂载。\n1 2 3 4 5 6 # .host:/ 是一个特殊地址，代表所有已启用的共享 # /mnt/hgfs 是挂载点 # -o allow_other 允许其他用户(包括你自己)访问，非常重要！ # -o uid=$(id -u) 将文件所有者设置为当前登录的用户 # -o gid=$(id -g) 将文件所属组设置为当前登录的用户 sudo vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other -o uid=$(id -u) -o gid=$(id -g) 现在 /mnt/hgfs 目录下就可以看到共享的文件了。\n不过，/mnt/hgfs/linux 这个路径太深，不方便日常使用，我们想将共享目录挂载在用户主目录下的 ~/works 目录中。\n首先在用户主目录下创建 works 目录作为挂载的目标。\n1 mkdir ~/works 然后同样使用 vmhgfs-fuse 工具来执行挂载。\n1 sudo vmhgfs-fuse .host:/ ~/works -o allow_other -o uid=$(id -u) -o gid=$(id -g) 现在，来验证一下命令效果：\n1 ls ~/works 你应该能看到 linux 目录。再进一步查看：\n1 ls ~/works/linux 此刻，你看到的就是 macOS 宿主机上那个共享文件夹里的所有内容了！\n然而手动挂载是临时的，一旦你重启虚拟机，挂载就会失效。要实现一劳永逸，请看下一步。\n实现开机自动挂载 为了避免每次重启都要手动敲一遍命令，我们需要将挂载信息写入 /etc/fstab 文件中。\n在 fstab 中，我们不能使用 $(id -u) 这样的命令。需要把用户 ID 和组 ID 的具体数字写进去。运行以下命令查看：\n1 2 id # 你会看到类似 uid=1000(ubuntu) gid=1000(ubuntu) ... 的输出 通常，第一个创建的用户的 UID 和 GID 都是 1000。请记下你自己的这两个数字。\n使用你熟悉的编辑器打开 /etc/fstab。\n1 sudo vi /etc/fstab 在文件的末尾，添加下面这一行。请注意，你需要将 /home/ubuntu/works 替换成你的实际路径，并将 uid=1000,gid=1000 替换成你自己的 ID。\n1 .host:/ /home/ubuntu/works fuse.vmhgfs-fuse defaults,allow_other,uid=1000,gid=1000 0 0 以后每次启动 Linux 虚拟机，VMware 的共享文件夹都会自动出现在 ~/works 目录下，方便随时访问。\n大功告成！\n","date":"2025-07-09T11:41:57+08:00","permalink":"https://mahaoliang.tech/p/%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E5%9C%A8-vmware-fusion-%E4%B8%AD%E5%AE%9E%E7%8E%B0%E4%B8%8E-linux-%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB/","title":"一步步教你在 VMware Fusion 中实现与 Linux 虚拟机的文件共享"},{"content":"今年我非常幸运地入选了“开源之夏”活动，参与的项目是面向 openEuler distroless 镜像的 SDF 自动生成工具开发。由于该项目是在 openEuler 上进行开发的，因此，搭建一个稳定可靠的 openEuler 开发环境便成了我的首要任务。\n我的主力设备是一台 M1 芯片的 MacBook Pro，由于去年 VMware Fusion 已经对个人用户免费，所以自然就选择在 VMware Fusion 上安装 openEuler。\n从 openEuler 官方镜像站下载 aarch64 架构最新的 openEuler 24.03 LTS SP1 镜像，使用 VMware Fusion 创建虚拟机，挂载镜像，启动后在 GRUB 界面选择“Install openEuler”，没想到就遇到了问题，安装过程卡住不动了：\n习惯性的截图问 Google AI studio，它列举了多个可能的原因，逐一排除确认，发现其中一个分析很有启发性：\n这个问题可能是由于内核在初始化虚拟显卡时卡住了\n于是尝试在 openEuler 的安装引导菜单，按 e 键进入编辑模式：\n继续截图让 Google AI studio 分析：\n您看到的这个界面是 GRUB 引导加载器的编辑模式。它允许您在启动 Linux 内核之前，临时修改传递给内核的参数。\nvideo=efifb:off video=VGA-1:640x480...: 这是一个重要线索！这行参数试图禁用 EFI 帧缓冲（efifb:off）并强制使用一个非常基础的 640x480 分辨率的 VGA 模式。这说明 openEuler 镜像为了在各种（尤其是老旧或奇怪的）硬件上都能启动而加入的“安全模式”参数。然而，这个配置与您的 VMware Fusion 环境冲突，导致了卡死。 请按照以下步骤操作：\n在 linux 那一行，手动删除掉现有的两个 video=... 参数，即删除 video=efifb:off 和 video=VGA-1:640x480-32@60me。 按 Ctrl+X 或 F10 启动。 按照 AI 的指示操作，奇迹发生了，系统顺利越过了卡死点，成功进入了图形化的安装界面！\nGemini 2.5 Pro 太厉害了，遇事不会问 Gemini，准没错！\n","date":"2025-07-07T20:26:30+08:00","permalink":"https://mahaoliang.tech/p/macos-%E4%B8%8A-vmware-fusion-%E6%97%A0%E6%B3%95%E5%AE%89%E8%A3%85-openeuler-%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","title":"macOS 上 VMWare Fusion 无法安装 OpenEuler 的问题解决"},{"content":"Python 虚拟环境概述 为什么需要虚拟环境 在 Python 开发中，不同的项目往往需要不同版本的 Python 解释器和第三方库。如果所有项目都共享同一套全局 Python 环境，很容易导致版本冲突和依赖混乱。虚拟环境通过创建隔离的 Python 运行环境，解决了这一问题，确保每个项目都能独立管理自己的依赖关系。\n虚拟环境的核心优势包括：\n环境隔离：不同项目的依赖相互隔离，避免版本冲突 系统保护：保持系统全局 Python 环境干净整洁，防止不必要的包污染 项目可移植性：通过requirements.txt文件记录依赖，方便在不同环境中重建相同的运行环境 版本控制：可以为每个项目指定特定的 Python 版本和库版本 venv 目录结构 venv 是 Python 3.3 及以上版本内置的虚拟环境创建工具，它的工作原理是通过创建一个独立的目录结构，其中包含 Python 解释器的符号链接和独立的site-packages目录。当你使用python -m venv myenv命令创建虚拟环境时，会生成以下关键文件和目录：\n1 2 3 4 5 6 7 8 myenv/ ├── bin/ │ ├── python -\u0026gt; # 指向系统Python解释器的符号链接 │ └── pip ├── lib/ │ └── python3.13/ │ └── site-packages/ # 第三方包安装目录 └── pyvenv.cfg # 环境配置文件 venv 基础操作指南 创建虚拟环境 要创建一个新的虚拟环境，使用以下命令：\n1 2 3 4 5 # macOS/Linux python -m venv myenv # Windows python -m venv myenv 其中，myenv是虚拟环境的名称，你可以根据需要修改。执行上述命令后，会在当前目录下创建一个名为myenv的文件夹，其中包含虚拟环境的所有文件和目录。\n激活虚拟环境 创建虚拟环境后，需要激活它才能使用：\n1 2 3 4 5 6 7 8 # macOS/Linux source myenv/bin/activate # Windows (命令提示符) myenv\\Scripts\\activate.bat # Windows (PowerShell) myenv\\Scripts\\Activate.ps1 激活成功后，你会注意到命令提示符前出现了虚拟环境的名称，例如：\n1 (myenv) $ 这表示你现在正在myenv虚拟环境中工作。\n激活虚拟环境的本质，实际上是执行了一个脚本，该脚本会：\n设置VIRTUAL_ENV环境变量指向虚拟环境的根目录 修改系统 PATH 环境变量，将虚拟环境的bin或Scripts目录添加到最前面 确保后续执行的python和pip命令都指向虚拟环境中的版本 停用虚拟环境 当你完成工作后，可以通过以下命令退出虚拟环境：\n1 $ deactivate 退出后，你将返回到系统的全局 Python 环境，虚拟环境的相关设置将不再生效。\n验证虚拟环境 在激活虚拟环境后，你可以通过以下方式验证环境是否正确设置：\n检查 Python 版本： 1 $ python --version 这将显示虚拟环境中使用的 Python 版本。\n检查 Python 解释器路径： 1 2 3 4 5 # macOS/Linux which python # Windows where python 输出应该是虚拟环境中 Python 解释器的路径，例如/path/to/your/project/myenv/bin/python（macOS/Linux）或C:\\path\\to\\your\\project\\myenv\\Scripts\\python.exe（Windows）。\n检查 pip 版本： 1 pip --version 这将显示虚拟环境中使用的 pip 版本。\n检查环境变量： 1 2 3 4 5 # macOS/Linux echo $VIRTUAL_ENV # Windows echo %VIRTUAL_ENV% 输出应该是虚拟环境的根目录路径。\n依赖管理与包操作 安装包 在激活的虚拟环境中，你可以使用pip命令安装项目所需的 Python 包。安装包的基本语法如下：\n1 pip install package_name 例如，要安装requests库，可以执行以下命令：\n1 pip install requests 如果需要安装特定版本的包，可以使用以下语法：\n1 pip install package_name==version_number 例如，要安装requests库的 2.26.0 版本：\n1 pip install requests==2.26.0 当你在虚拟环境中安装包时，这些包会被安装到虚拟环境的site-packages目录中。具体路径如下：\n1 2 3 4 5 # macOS/Linux myenv/lib/python3.x/site-packages/ # Windows myenv/Lib/site-packages/ 这个目录是虚拟环境隔离的关键，确保包不会被安装到系统全局环境中。\n更新包 当需要更新虚拟环境中的包时，可以使用以下命令：\n1 pip install --upgrade package_name 例如，要更新requests库到最新版本：\n1 pip install --upgrade requests 卸载包 当某个包不再需要时，可以使用以下命令卸载：\n1 pip uninstall package_name 例如，要卸载requests库：\n1 pip uninstall requests 卸载时，pip 会提示你确认是否卸载该包，输入y确认即可。\n管理依赖列表 对于较大的项目，管理所有依赖和它们的版本可能会变得复杂。pip允许你使用requirements.txt文件来跟踪这些依赖。\n生成依赖列表： 1 pip freeze \u0026gt; requirements.txt 这将在当前目录下创建一个requirements.txt文件，其中包含所有已安装包及其版本号\n安装依赖列表： 1 pip install -r requirements.txt 这将安装requirements.txt文件中列出的所有包及其指定版本。\n更新依赖列表： 当你安装或更新包后，需要重新生成requirements.txt文件：\n1 pip freeze \u0026gt; requirements.txt requirements.txt文件的格式通常如下：\n1 2 3 4 5 certifi==2025.7.14 charset-normalizer==3.4.2 idna==3.10 requests==2.32.4 urllib3==2.5.0 VS Code 集成 VS Code 对 Python 虚拟环境提供了良好的支持，以下是在 VS Code 中使用 venv 的步骤：\n安装 Python 扩展： 打开 VS Code，按下Ctrl+Shift+X（Windows/Linux）或Cmd+Shift+X（macOS）打开扩展市场，搜索并安装 \u0026ldquo;Python\u0026rdquo; 扩展。\n打开项目目录： 使用File \u0026gt; Open Folder打开包含虚拟环境的项目目录。\n创建新终端： 当你创建新终端时，VS Code 会自动激活当前选择的虚拟环境，命令提示符前会显示环境名称。\n总结 在本文中，我们详细介绍了 Python 虚拟环境（venv）的使用方法和工作原理。\n虚拟环境基本使用 操作类型 macOS/Linux 命令 Windows（命令提示符）命令 Windows（PowerShell）命令 创建虚拟环境 python -m venv myenv python -m venv myenv python -m venv myenv 激活虚拟环境 source myenv/bin/activate myenv\\Scripts\\activate.bat myenv\\Scripts\\Activate.ps1 停用虚拟环境 deactivate deactivate deactivate 验证 Python 版本 python --version python --version python --version 验证 Python 解释器路径 which python where python where python 验证 pip 版本 pip --version pip --version pip --version 验证环境变量 echo $VIRTUAL_ENV echo %VIRTUAL_ENV% echo $env:VIRTUAL_ENV 依赖管理基本使用 操作类型 操作说明 执行命令 安装包 安装指定第三方包（默认最新版本） pip install package_name 安装特定版本包 安装指定版本的第三方包，避免版本冲突 pip install package_name==version_number 更新包 将已安装的包更新到最新版本 pip install --upgrade package_name 卸载包 移除已安装的第三方包 pip uninstall package_name 生成依赖列表 将当前环境中所有已安装包及版本信息导出到 requirements.txt 文件 pip freeze \u0026gt; requirements.txt 安装依赖列表 根据 requirements.txt 文件安装所有指定包及对应版本 pip install -r requirements.txt 查看已安装包 列出当前环境中所有已安装的第三方包及版本 pip list 查看包详情 显示指定包的详细信息（如版本、依赖、安装路径等） pip show package_name 检查可更新的包 列出当前环境中可更新的包及最新版本 pip list --outdated 最佳实践建议 项目结构 在项目根目录下创建名为.venv的虚拟环境 这样可以保持项目结构的清晰，并方便激活虚拟环境 依赖管理 使用requirements.txt文件记录项目依赖 在提交代码时，包含requirements.txt文件，而不是整个虚拟环境目录 使用pip freeze \u0026gt; requirements.txt生成依赖列表 环境激活 在开发过程中，始终激活虚拟环境后再执行 Python 命令或安装包 版本控制 将虚拟环境目录添加到.gitignore文件中 提交requirements.txt文件，确保其他开发者可以复现相同的环境 虚拟环境是 Python 开发中不可或缺的工具，它帮助开发者保持环境的整洁和项目的可维护性。随着你的项目规模和复杂性的增加，熟练掌握虚拟环境的使用将成为一项重要的技能。\n","date":"2025-07-01T16:21:43+08:00","permalink":"https://mahaoliang.tech/p/python-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86venv-%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97/","title":"Python 虚拟环境管理：venv 实用指南"},{"content":"作为 Python 初学者，使用 pyenv 来管理多版本 Python 环境是一个明智的选择。pyenv 允许你轻松安装、切换和管理多个 Python 版本，同时保护系统自带的 Python 不被修改。本指南将详细介绍在 macOS 上安装和使用 pyenv 的全过程，包括安装步骤、管理不同 Python 版本、保护系统 Python 等操作方法。\n准备工作 检查 Homebrew 安装 在开始安装 pyenv 之前，首先需要确保你已经安装了 Homebrew。Homebrew 是 macOS 上的包管理器，方便我们安装各种工具和依赖。可以在终端中运行以下命令检查：\n1 2 $ brew --version Homebrew 4.5.8 安装 Xcode 命令行工具 macOS 上编译安装 Python 需要一些开发工具，这些工具可以通过 Xcode 命令行工具提供。运行以下命令安装：\n1 $ xcode-select --install 这会弹出一个安装窗口，按照提示完成安装即可。\n安装 pyenv 使用 Homebrew 安装 pyenv 在 macOS 上安装 pyenv 最简单的方法就是使用 Homebrew。在终端中运行以下命令：\n1 $ brew install pyenv 这一步会下载并安装 pyenv 及其依赖。安装完成后，你可以通过以下命令验证安装是否成功：\n1 2 $ pyenv --version pyenv 2.6.3 如果看到版本号，说明安装成功。\n配置环境变量 安装完成后，需要将 pyenv 添加到你的 Shell 配置文件中，以便在任何终端会话中都能使用。根据你使用的 Shell 类型（zsh 或 bash），打开相应的配置文件。以 zsh 为例，打开 ${HOME}/.zshrc 文件，在文件末尾添加以下内容：\n1 2 3 export PYENV_ROOT=\u0026#34;$HOME/.pyenv\u0026#34; [[ -d $PYENV_ROOT/bin ]] \u0026amp;\u0026amp; export PATH=\u0026#34;$PYENV_ROOT/bin:$PATH\u0026#34; eval \u0026#34;$(pyenv init - zsh)\u0026#34; 这些配置将：\n设置 pyenv 的根目录 将 pyenv 的二进制目录添加到系统 PATH 中 初始化 pyenv 环境 保存文件后，在终端中运行以下命令使配置生效：\n1 source ${HOME}/.zshrc 管理 Python 版本 查看可用 Python 版本 安装 pyenv 后，你可以查看所有可用的 Python 版本：\n1 2 3 4 5 6 7 8 $ pyenv install --list Available versions: 2.1.3 2.2.3 2.3.7 2.4.0 2.4.1 ... 这会列出所有可通过 pyenv 安装的 Python 版本，包括最新版本和旧版本。\n安装特定版本的 Python 要安装特定版本的 Python，使用以下命令：\n1 $ pyenv install \u0026lt;version\u0026gt; 例如，要安装 Python 3.13.5，可以运行：\n1 $ pyenv install 3.13.5 安装过程可能需要一些时间，因为 pyenv 会从源代码编译 Python。你会看到类似以下的提示：\n1 2 3 4 5 6 7 8 python-build: use openssl@3 from homebrew python-build: use readline from homebrew Downloading Python-3.13.5.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.13.5/Python-3.13.5.tar.xz Installing Python-3.13.5... python-build: use readline from homebrew python-build: use zlib from xcode sdk Installed Python-3.13.5 to /Users/haoliangma/.pyenv/versions/3.13.5 查看已安装的 Python 版本 安装完成后，可以使用 pyenv versions 查看已安装的 Python 版本：\n1 2 3 4 5 $ pyenv versions system 2.7.18 * 3.11.8 (set by /Users/haoliangma/.pyenv/version) 3.13.5 第一行 system 表示系统自带的 Python 版本，通常由操作系统预装。当前未被激活（没有 * 标记）\n第二行 2.7.18 表示通过 pyenv 安装的 Python 2.7.18 版本。当前未被激活（没有 * 标记）。\n第三行 * 3.11.8 (set by /Users/haoliangma/.pyenv/version) 表示当前激活的 Python 版本，该版本是通过全局配置文件 /Users/haoliangma/.pyenv/version 设置的默认版本。\n第四行 3.13.5 表示通过 pyenv 安装的 Python 3.13.5 版本，同样没有被激活。\n设置全局 Python 版本 要设置系统默认的 Python 版本，可以使用以下命令：\n1 $ pyenv global \u0026lt;version\u0026gt; 例如，要将 Python 3.13.5 设置为全局默认版本：\n1 $ pyenv global 3.13.5 再次使用 pyenv versions 查看已安装的版本：\n1 2 3 4 5 $ pyenv versions system 2.7.18 3.11.8 * 3.13.5 (set by /Users/haoliangma/.pyenv/version) 发现 3.13.5 版本已经被激活。\n可以通过以下命令验证：\n1 2 $ python --version Python 3.13.5 设置局部 Python 版本 在项目目录中，你可以设置特定于该项目的 Python 版本。进入项目目录，运行：\n1 $ pyenv local \u0026lt;version\u0026gt; 这会在当前目录下创建一个名为.python-version的文件，记录当前项目使用的 Python 版本。当你进入该目录时，pyenv 会自动切换到指定的 Python 版本。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ cd pythonprojects $ pyenv local 3.11.8 $ pyenv versions system 2.7.18 * 3.11.8 (set by /Users/haoliangma/works/pythonprojects/.python-version) 3.13.5 $ cd .. $ pyenv versions system 2.7.18 3.11.8 * 3.13.5 (set by /Users/haoliangma/.pyenv/version) 临时使用特定版本 如果你只需要在当前终端会话中临时使用某个 Python 版本，可以使用：\n1 $ pyenv shell \u0026lt;version\u0026gt; 例如：\n1 2 3 4 5 6 7 8 9 10 11 $ pyenv versions system 2.7.18 3.11.8 * 3.13.5 (set by /Users/haoliangma/.pyenv/version) $ pyenv shell 3.11.8 $ pyenv versions system 2.7.18 * 3.11.8 (set by PYENV_VERSION environment variable) 3.13.5 这会覆盖全局和局部设置，仅在当前终端会话中生效。要恢复到之前的设置，可以使用：\n1 $ pyenv shell --unset 卸载 Python 版本 当你不再需要某个 Python 版本时，可以使用以下命令卸载：\n1 $ pyenv uninstall \u0026lt;version\u0026gt; 保护系统 Python macOS 系统自带了一个 Python 解释器，通常位于/usr/bin/python3。这个 Python 版本是系统正常运行所必需的，修改或删除它可能导致系统不稳定或某些功能无法正常工作。因此，保护系统 Python 非常重要。\npyenv 不会自动管理或修改系统 Python。当你安装新的 Python 版本时，它们会被安装在~/.pyenv/versions目录下，而不是系统路径中。这意味着系统 Python 始终保持不变，不会受到 pyenv 安装的版本的影响。\n你可以通过以下命令验证系统 Python 是否未被修改：\n1 2 $ which python /Users/haoliangma/.pyenv/shims/python 可以看出，你当前使用的是 pyenv 管理的 Python 版本。\n为了确保系统 Python 不被覆盖，你应该避免使用sudo安装或升级 Python。此外，在设置全局 Python 版本时，应确保不将系统 Python 设置为全局版本。\n如果你不小心覆盖了系统 Python 的某些行为，你可以通过重新安装 Xcode 命令行工具来恢复。运行：\n1 $ xcode-select --install 这会重新安装系统工具，包括系统 Python。\n总结 通过本指南，你应该已经掌握了在 macOS 上使用 pyenv 管理 Python 版本的基本技能。以下是关键点回顾：\n安装 pyenv：使用 Homebrew 安装 pyenv 和相关插件，确保正确配置环境变量。\n管理 Python 版本\n命令 描述 pyenv install -list 查看可安装版本 pyenv install 安装指定版本 pyenv versions 查看已安装版本 pyenv global 设置全局默认版本 pyenv local 为当前目录设置版本 pyenv shell 为当前 Shell 设置版本 pyenv uninstall 卸载版本 保护系统 Python：pyenv 不会自动管理系统 Python，确保系统 Python 不被覆盖是使用 pyenv 的重要原则。 通过使用 pyenv，你可以在保持系统 Python 完整的同时，灵活地管理多个 Python 版本，使你的 Python 开发更加高效和安全。\n","date":"2025-06-14T13:18:30+08:00","permalink":"https://mahaoliang.tech/p/%E5%9C%A8-macos-%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8-pyenv/","title":"在 macOS 上安装和使用 pyenv"},{"content":"\n","date":"2025-05-05T10:38:49+08:00","permalink":"https://mahaoliang.tech/p/ai-%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%932025-%E5%B9%B4-5-%E6%9C%88%E7%89%88/","title":"AI 工具总结（2025 年 5 月版）"},{"content":"Zsh 是一种专门为交互式使用而设计的 Shell，同时也是一种强大的脚本语言，集成了 bash、ksh 和 tcsh 的许多有用特性，并添加了许多独特的功能。\n本文将指导您在 macOS 和 Linux 系统上安装 Zsh、Oh My Zsh 以及其常用插件，并展示如何配置 Oh My Zsh，以打造一个高效的命令行工作环境。\n安装 Zsh macOS brew install zsh Ubuntu sudo apt install zsh RHEL sudo yum update \u0026amp;\u0026amp; sudo yum -y install zsh 验证安装的 Zsh 版本 1 2 $ zsh --version zsh 5.8.1 (x86_64-ubuntu-linux-gnu) 设置 Zsh 为缺省 shell 1 $ chsh -s $(which zsh) 退出并重新登录。\n安装 Oh My Zsh Oh My Zsh 是一个开源、社区驱动的 Zsh 配置管理框架，，提供了 300 多个可选插件和 140 多个主题，并且内置了自动更新工具。\n使用下面的命令安装：\n1 $ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 安装 zsh-autosuggestions zsh-autosuggestions 为 zsh shell 提供了类似 Fish shell 的自动建议功能的插件，该插件可以根据历史记录和自动补全来为用户提供命令建议。\n将插件 clone 到 $ZSH_CUSTOM/plugins：\n1 $ git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 然后在 ${HOME}/.zshrc 启用插件：\n1 plugins=(git zsh-autosuggestions) 在命令行输入命令时，zsh-autosuggestions 会根据命令历史或命令补全进行建议提示。那么如何接受建议呢？\nBash 和 Zsh 这样的 Unix shell 提供了两种主要的编辑模式：Emacs 模式和 Vi 模式，也就是说可以使用 Emacs 或 Vi 的快捷键来编辑命令行。Emacs 模式是缺省模式。\n在 zsh-autosuggestions 的缺省配置文件中，定义接受建议的快捷键：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ... # Widgets that accept the entire suggestion (( ! ${+ZSH_AUTOSUGGEST_ACCEPT_WIDGETS} )) \u0026amp;\u0026amp; { typeset -ga ZSH_AUTOSUGGEST_ACCEPT_WIDGETS ZSH_AUTOSUGGEST_ACCEPT_WIDGETS=( forward-char end-of-line vi-forward-char vi-end-of-line vi-add-eol ) } ... 如果命令行处于 Emacs 模式，那么：\nctrl-f 或 ctrl-e 跳到行尾接受当前的建议 option-f 向前前进一个单词并接受建议 同样，如果命令行处于 vi 模式，那么就使用对应的 vi 键盘绑定接受建议。\n配置 Oh My Zsh Oh My Zsh 有非常多的内置插件，你也可以安装第三方插件，就像上面安装的 zsh-autosuggestions。\nOh My Zsh 也内置了多个 主题 供你选择。\n我们可以编辑 ${HOME}/.zshrc，配置 Oh My Zsh 的插件、主题，以及其他一些定制化设置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ... # 设置主题 ZSH_THEME=\u0026#34;bira\u0026#34; # 启用插件 plugins=(git z zsh-autosuggestions) # 命令别名 alias mkdir=\u0026#39;mkdir -v\u0026#39; alias mv=\u0026#39;mv -v\u0026#39; alias cp=\u0026#39;cp -v\u0026#39; alias rm=\u0026#39;rm -v\u0026#39; alias ln=\u0026#39;ln -v\u0026#39; # 配置zsh-autosuggestions export ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=\u0026#34;fg=#ff00ff,bg=cyan,bold,underline\u0026#34; export ZSH_AUTOSUGGEST_STRATEGY=(history completion) ","date":"2025-01-05T21:06:07+08:00","permalink":"https://mahaoliang.tech/p/zsh-%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/","title":"Zsh 的安装和配置"},{"content":"\n计算机系统与组成原理 极客时间：深入浅出计算机组成原理 Computer Systems: A Programmer\u0026rsquo;s Perspective 从程序员的角度学习计算机系统，了解计算机系统的各个方面，包括硬件、操作系统、编译器和网络。这本书涵盖了数据表示、C 语言程序的机器级表示、处理器架构、程序优化、内存层次结构、链接、异常控制流（异常、中断、进程和 Unix 信号）、虚拟内存和内存管理、系统级 I/O、基本的网络编程和并发编程等概念。这些概念由一系列有趣且实践性强的实验室作业支持。 Computer Systems: A programmer\u0026rsquo;s Perspective 视频课 Computer Science from the Bottom Up 采用“从下到上”的方法，从最基础的二进制、数据表示开始，逐步深入计算机内部工作原理，目的是帮助读者真正掌握计算机科学的基础知识。 Putting the “You” in CPU 深入探讨了计算机系统的工作原理，包括 CPU 的基本操作、系统调用、多任务处理、内存管理以及程序的执行过程。 编码 从二进制编码、数据表示到计算机体系结构、操作系统等多个重要主题，从根本上理解计算机的工作原理。 漫画计算机原理 趣话计算机底层技术 计算机底层的秘密 穿越计算机的迷雾 嵌入式 C 语言自我修养 C 语言 征服 C 指针 彻底理解和掌握指针的各种用法和技巧 C 专家编程 Sun 公司编译器和 OS 核心开发团队成员，对 C 的历史、语言特性、声明、数组、指针、链接、运行时、内存等问题进行了细致的讲解和深入的分析 C from Scratch 一个学习 C 语言的从零开始的路线图，包括推荐的课程、项目和资源，以及进阶到 x86-64 汇编语言和操作系统内部的指导。 极客时间：深入 C 语言和程序运行原理 cdecl 将 C 语言声明转换为英文描述，例如将这样复杂的声明 void (\\*signal(int, void (\\*)(int)))(int) 转换为文字描述：“declare signal as function (int, pointer to function (int) returning void) returning pointer to function (int) returning void” 程序运行原理 Online Compiler, Visual Debugger 独特的逐步可视化调试工具，强烈推荐！ 程序是怎样跑起来的 程序员的自我修养：链接、装载与库 如何从对象文件中导入和执行代码 part1 part2 part3 x86/x64 CPU architecture: the stack \u0026amp; stack frames x86/x64 CPU 架构中的栈（Stack）及其工作机制，包括栈的数据结构特性、CPU 中栈的管理、栈与堆的区别、栈帧的创建与销毁，以及栈的性能优势。 Driving Compilers 关于如何使用编译器创建可执行文件的深入知识，涵盖编译器驱动程序、预处理器 cpp、编译器 cc、链接器 ld 以及 Linux 加载器的概念。 Linux 使用 极客时间：Linux 实战技能 100 讲 Efficient Linux at the Command Line 像黑客一样使用命令行 Linux Foundation 的认证考试 LFCA 和 LFCS Learning Modern Linux Linux From Scratch step-by-step instructions for building your own customized Linux system entirely from source. Linux 内核 Linux 是怎么工作的 Linux 技术内幕 Linux 内核设计与实现 Linux Kernel Development 深入理解 Linux 进程与内存 极客时间：Linux 内核技术实战课 极客时间：编程高手必学的内存知识 极客时间：容器实战高手课 深入理解 Linux 网络 交互式的 Linux 内核地图 Linux 系统编程 Linux/UNIX系统编程手册 The Linux Programming Interface: A Linux and UNIX System Programming Handbook UNIX 环境高级编程 Advanced Programming in the UNIX Environment CS 341: System Programming 伊利诺伊大学香槟分校 CS 341 课程使用，介绍 C 语言和 Linux 系统编程知识。 网络 趣谈网络协议 极客时间：Web 协议详解与抓包实战 图解 TCP/IP 图解 HTTP 网络是怎样连接的 数据结构和算法 极客时间：数据结构与算法之美 极客时间：算法面试通关 40 讲 极客时间：常用算法 25 讲 极客时间：算法训练营 Hello 算法 动画图解、一键运行的数据结构与算法教程 通过动画可视化数据结构和算法 算法刷题 Leetcode 一个广受欢迎的在线编程题库 Neetcode 另一个在线编程练习平台 代码随想录 LeetCode 刷题攻略 算法通关手册 850+ 道「LeetCode 题目」详细解析 综合 计算机自学指南 (GitHub 仓库) YouTube 视频课：Crash Course Computer Science Preview 计算机教育中缺失的一课 Developer Roadmaps 为开发者提供学习路线图和指南 Online Coding Classes – For Beginners 3000 小时的免费课程，涵盖了编程涉及到的方方面面 交互式教程 Grep by example 如何使用命令行工具 grep 进行文本搜索的交互式指南 Learn Git Branching 一个交互式的在线教程，帮助用户学习并练习 Git 的基本使用方法 在线课程 educative 为开发者提供交互式在线课程，重点关注技术领域的知识与技能 edX 由麻省理工学院（MIT）和哈佛大学共同创立的在线教育平台 exercism 专注于通过有趣且具有挑战性的练习问题、支持建设性同行评审机制来促进积极参与和技能提升，从而培养对各种现代计算范式的熟练掌握。 技术面试 Cracking the coding interview book 一本深受程序员喜爱的面试指南书 编程面试大学 涵盖了算法、数据结构、面试准备和工作机会等主题，帮助你准备大公司的技术面试 interviewing.io 一个提供模拟技术面试的平台 Pramp 一个模拟面试平台 Meetapro 一个可以找到专业人士进行模拟面试的网站 PPResume 一个基于 LaTeX 的简历生成器，目标是帮助人们在几分钟内创建一份精美的简历，并提供极高质量的排版和 PDF 输出。 大语言模型 Learn Prompting 一个开源的、多元化社区构建的课程，旨在提供完整、公正的提示工程知识。 提示工程指南 介绍大语言模型（LLM）相关的论文研究、学习指南、模型、讲座、参考资料、大语言模型能力及其与其他工具的对接。 面向开发者的大模型手册 基于吴恩达大模型系列课程的翻译和复现项目，涵盖了从 Prompt Engineering 到 RAG 开发的全部流程，为国内开发者提供了学习和入门 LLM 相关项目的方式。 LLM 应用开发实践笔记 作者在学习基于大语言模型的应用开发过程中总结出来的经验和方法，包括理论学习和代码实践两部分。 动手学大模型应用开发 面向小白开发者的大模型应用开发教程，基于阿里云服务器，结合个人知识库助手项目，通过一个课程完成大模型开发的重点入门。 iOS 开发 iOS \u0026amp; Swift - The Complete iOS App Development Bootcamp The 100 Days of SwiftUI Stanford CS193p - Developing Apps for iOS iOS and SwiftUI for Beginners Meta iOS Developer Develop in Swift Tutorials 苹果官方教程 SwiftUI Tutorials 苹果官方教程 计算机科学史 信息简史 ","date":"2024-08-24T15:51:30+08:00","permalink":"https://mahaoliang.tech/p/%E5%A4%A7%E5%AD%A6%E7%94%9F%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E4%B8%8D%E5%AE%8C%E5%85%A8%E5%88%97%E8%A1%A8/","title":"大学生计算机专业学习资源不完全列表"},{"content":"本文是我参加《第一期傲来操作系统（EulixOS）训练营》的项目实习报告。\n傲来操作系统（EulixOS）是由中科院软件所 / 中科南京软件技术研究院团队基于 openEuler 打造的操作系统发行版。\n任务目标 Helm 是一个 Kubernetes 的包管理工具，它可以帮助用户定义、安装和升级运行在 Kubernetes 上的应用程序。\nHelm chart test 是一个用于测试 Helm 图表的 CLI 工具，用于测试 Helm chart 的拉取请求，能自动检测与目标分支相比已经更改的 chart。\n本任务计划在 ARM 和 RISC-V 架构上运行 Helm 和 Helm chart Test 的测试，以此来对比这两种平台上云原生软件的成熟度。\nHelm 的单元测试 分析 Helm 的 Makefile 文件，发现 test-unit 目标是用来运行单元测试的：\n1 2 3 4 5 .PHONY: test-unit test-unit: @echo @echo \u0026#34;==\u0026gt; Running unit tests \u0026lt;==\u0026#34; GO111MODULE=on go test $(GOFLAGS) -run $(TESTS) $(PKG) $(TESTFLAGS) 可以看出，helm 的单元测试可以直接通过 go test 命令来执行。\n查看 go.mod 文件，确定该项目使用的 Go 版本是 1.22.0：\n1 2 3 4 5 6 7 8 module helm.sh/helm/v3 go 1.22.0 require ( github.com/BurntSushi/toml v1.3.2 ... } Helm chart test 的单元测试 Helm chart test 项目使用 build.sh 脚本进行构建发布。分析 build.sh 发现，在每次构建前，会使用 go test -race ./... 运行单元测试：\n1 2 3 4 ... go test -race ./... goreleaser \u0026#34;${goreleaser_args[@]}\u0026#34; ... 查看go.mod文件，确定该项目使用的 Go 版本是 1.22.0：\n1 2 3 4 5 6 module github.com/helm/chart-testing/v3 go 1.22.0 toolchain go1.22.4 ... 自动化执行测试 helm 和 helm chart test 的单元测试都可以直接通过 go test 命令来执行。我们可以使用 bash 编写脚本使测试过程自动化。\n这个脚本的主要流程为：\n自动识别和配置：脚本首先检测硬件平台，然后自动下载并在测试目录下安装 Go，不干扰系统中的其他设置或版本。 环境设置：配置必要的环境变量，确保测试在适当的环境下执行。 代码仓库管理：自动从配置的 Git 仓库地址克隆代码到本地指定目录。 测试执行：运行单元测试，并将结果输出到报告文件中。 性能数据收集：通过调用 performance_counter_920.sh 收集和记录测试期间的性能指标。 为了避免网络环境对测试影响，脚本可以自定义配置：\n通过 GO_BASE_URL 定义 go 安装包下载网址 通过 REPO_URL 定义项目源码仓库的地址。可以提前将项目从 GitHub 同步到 Gitee。 通过 GOPROXY 定义 Go 镜像地址。缺省设置为 GOPROXY=https://goproxy.cn，从国内镜像下载 moudle。 另外，helm 在测试插件功能时，会访问 https://github.com/adamreese/helm-env 。由于网络环境问题，涉及的测试经常会失败。所以我将 helm-env 项目同步到了 gitee，并修改了测试案例 vcs_installer_test.go，让它从 gitee 下载插件，保证了测试运行的稳定。\n两个项目的自动化测试脚本都已经提交到了 gitee，分别为：\nhttps://gitee.com/mahaoliang/helm-test https://gitee.com/mahaoliang/helm-chart-test 测试结果 下面是在 ARM 上运行的 helm 的测试结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Avg 10 times duration time: 24558698523 Avg 10 times task clock: 130738.640 Avg 10 times cpu-cycles: 290310169669 Avg 10 times instructions: 269526073395 Avg 10 times cache references: 95029267023 Avg 10 times cache misses: 764800123 Avg 10 times branches: \u0026lt;not Avg 10 times branch misses: 647318994 Avg 10 times L1 dcache loads: 95029267023 Avg 10 times L1 dcache load misses: 764800123 Avg 10 times LLC load misses: 480961351 Avg 10 times LLC load: 1156309818 Avg 10 times IPC: 0.928 helmrequiresearchfil.txt has been deleted Number of packages: 50 Analyzing test results in /home/cloud2/helm-test/reports/20240628135442/test_result Total tests: 1327 Passed tests: 1327 Failed tests: 0 一共运行了 1327 个测试用例，全部通过。\n在 ARM 上运行的 helm chart test 的测试结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Avg 10 times duration time: 704309016 Avg 10 times task clock: 5337.880 Avg 10 times cpu-cycles: 10071410187 Avg 10 times instructions: 8342502186 Avg 10 times cache references: 3300195194 Avg 10 times cache misses: 34476953 Avg 10 times branches: \u0026lt;not Avg 10 times branch misses: 39065962 Avg 10 times L1 dcache loads: 3300195194 Avg 10 times L1 dcache load misses: 34476953 Avg 10 times LLC load misses: 15971288 Avg 10 times LLC load: 50427439 Avg 10 times IPC: 0.828 Number of packages: 8 Analyzing test results in /home/cloud2/helm-chart-test/reports/20240628140012/test_result Total tests: 92 Passed tests: 92 Failed tests: 0 一共运行了 92 个测试用例，全部通过。\n测试过程详细输出的原始文件如下：\nhelm 的 go test 输出 helm 测试过程的 perf 统计指标 helm chart test 的 go test 输出 helm chart test 测试过程的 perf 统计指标 到测试截止时间，RISC-V 机器还未准备好，因此没有运行 RISC-V 架构的测试。不过我们已经提供了自动化测试脚本，可以直接在 RISC-V 架构的机器上运行，为后面在 RISC-V 上的测试做好了准备。\n","date":"2024-06-29T10:44:41+08:00","permalink":"https://mahaoliang.tech/p/helm-%E5%92%8C-helm-chart-test-%E5%9C%A8-arm-%E5%92%8C-risv-v-%E4%B8%8A%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/","title":"Helm 和 Helm chart Test 在 ARM 和 RISV-V 上的自动化测试"},{"content":"文本准备 要创建一个以 .py 扩展名结尾的文本文件，你可以按照以下步骤进行操作：\n打开文本编辑器。\n你可以使用操作系统自带的文本编辑器（如记事本、TextEdit 等），或者使用专业的代码编辑器（如 Visual Studio Code、Sublime Text、Atom 等）。\n在文本编辑器中创建一个新文件。\n将你的 Python 代码复制粘贴到新文件中。 保存文件时，指定文件名并确保使用 .py 作为文件的扩展名。 例如，你可以将文件命名为 plot_example.py。\n代码示例（画的是一个 y=x^2 的图）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import numpy as np # 准备数据 x = np.linspace(-10, 10, 100) # 在 -10 到 10 之间生成 100 个均匀分布的点 # 计算对应的 y 值 y = x ** 2 # 创建图形并设置标题 plt.figure() plt.title(\u0026#34;Plot Example\u0026#34;) # 绘制折线图 plt.plot(x, y) # 显示图形 plt.show() repr 运行 我在 Mac 上用的是visual studio code， 点击文件，用 VS code 打开。 打开后，假如没装 python 的话，会显示要 install python 编译器，下载就可以运行了了 ","date":"2023-09-15T15:07:58+08:00","permalink":"https://mahaoliang.tech/p/%E5%A6%82%E4%BD%95%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BB%98%E5%88%B6%E6%95%B0%E5%AD%A6%E5%87%BD%E6%95%B0/","title":"如何用命令行绘制数学函数"},{"content":"视频逐帧提取 运用脚本来完成手动工作，即 n 秒一次截屏 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 tell application \u0026#34;IINA\u0026#34; reopen activate delay 0.5 tell application \u0026#34;System Events\u0026#34; keystroke (ASCII character 32) delay 0.1 end tell repeat tell application \u0026#34;System Events\u0026#34; keystroke \u0026#34;s\u0026#34; using {command down} end tell delay 0.5 end repeat end tell 这里的第三个 delay 是来控制截屏间隙的，delay 0.5就是 0.5 秒截一次屏。\n这个脚本只试用于 Mac 电脑，因为 command+s 是 Mac 上的快捷键。\npng 转 svg，再转 png svg 就是字符矢量图，但是它不能导入视频软件来制作视频，所以还要再转回 png。 copy pics to tencent server 1 scp $HOME/Pictures/Screenshots/*.png mahaoliang:/home/ubuntu/works/pics/ 这里我是上传到服务器上搞的， install app 1 2 3 sudo apt-get install caca-utils sudo apt-get install librsvg2-bin sudo apt install imagemagick run script 1 ./run.sh 因为有很多张图片，所以写了一个脚本 run.sh，就是将 png-\u0026gt;svg-\u0026gt;png 的动作重复，命令如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # clean mkdir -p \u0026#34;${svg}\u0026#34; mkdir -p \u0026#34;${output}\u0026#34; # 使用循环遍历目录中的每个文件 for file in \u0026#34;${pics}\u0026#34;/*.png; do # 检查文件是否是普通文件 if [[ -f $file ]]; then filename=$(basename \u0026#34;$file\u0026#34;) filename=\u0026#34;${filename%.*}\u0026#34; echo \u0026#34;processing $file\u0026#34; # 这里可以添加你的处理逻辑 img2txt -W 200 -f svg \u0026#34;$file\u0026#34; \u0026gt;${svg}/\u0026#34;${filename}\u0026#34;.svg fi done for file in \u0026#34;${svg}\u0026#34;/*.svg; do # 检查文件是否是普通文件 if [[ -f $file ]]; then filename=$(basename \u0026#34;$file\u0026#34;) filename=\u0026#34;${filename%.*}\u0026#34; echo \u0026#34;processing $file\u0026#34; # 这里可以添加你的处理逻辑 rsvg-convert \u0026#34;${file}\u0026#34; \u0026gt;${output}/\u0026#34;${filename}\u0026#34;.png fi done #convert ${output}/*.png output.gif tar -zcvf output-${timestamp}.tar.gz ${output} 这里面#convert ${output}/*.png output.gif,可以把#去掉，这样就可以直接制作字符动图了（gif）。 download 1 scp mahaoliang:/home/ubuntu/works/output.png . 动画制作 我用的是苹果的 final cut pro，试用期是 90 天，假如到期了话就可以输入一下代码，重置时限： 1 2 3 4 cd ~ cd Library/Application\\ Support ll -a rm .ffuserdata 将所有图片依次导入软件，建立复合片段，再调整速度就好了。 结尾 最后送大家一个 GIF\n视频 https://cdn.mahaoliang.tech/images/202309082303161.mp4\n","date":"2023-09-08T20:06:23+08:00","permalink":"https://mahaoliang.tech/p/%E5%AD%97%E7%AC%A6%E5%8A%A8%E7%94%BB%E5%88%B6%E4%BD%9C/","title":"字符动画制作"},{"content":"网址 直接推网站：DeGraeve.com\n步骤 图片要准备 URL 的链接，例如图中的https://www.degraeve.com/images/lcsm.gif 可以看到下面一行有三个选项，ASCII art、color HTML 和 RTTY。以下分别是这三个的效果图 可以发现三者，有颜色的还原度最高，第一个还原度第二，第三个最差。 怎么选就看个人了。\n总结 这个网站还有很多其他的功能，因该是为数不多的优良的免费工具了。\n","date":"2023-09-04T12:57:56+08:00","permalink":"https://mahaoliang.tech/p/%E5%9B%BE%E7%89%87%E8%BD%AC%E5%AD%97%E7%AC%A6%E7%BD%91%E7%AB%99%E5%88%86%E4%BA%AB/","title":"图片转字符网站分享"},{"content":"0. 前言 北京时间晚上 11:43，舍友，唯一一个舍友，上床睡觉去了。现在是琪亚娜时间！！！\n$MUSIC=I Really Want to Stay at Your House$\n1. 我的世界树 我这个人性格上跟村上春树很像，不折不扣的个人主义。用中国人的一个词来讲，就是天性凉薄的人。我之前写过，由于我这十八年从没有表达过自己，导致了我的情感淡化，麻木，成了无感之人。看医生的时候，问我在某个特定的情境下有什么感受，或是对我之前的经历有什么感受，我完全回答不上来，“我母鸡呀”。我写这篇文章呢，并不是要给谁看的，而是在练习自我表达，缓解病情，虽然这“天性凉薄”可能已经刻在了我的 DNA 里啦。\n我并不了解我的父母，在这十几年里，感觉像跟陌生人一样生活在一起，这一切大部分是我的问题，谁叫我天性凉薄呢。我妈每次都唠叨，假如我现在回家，她一定会先叫我洗手，但我一定不会洗。我爸好沉默的，以前我小学的时候，他辅导我数学经常发火，于是我家买了一个一米厚的木头长桌。别问发火与买桌子有啥关系，问就是一米厚拍不断。我呢，就基本上在打游戏啦。在学校里累成狗，回家最快，最容易上手的就是打游戏啊。初二时，我晚上两点偷偷爬起来打平板。平板就在客厅的长桌上，我每次都得摸着过去，因为要经过爸妈的房间，每次拿到 iPad 回到房间里心都得猛跳两下。高三时，高考前两个月，我白天在家里打游戏，晚上和爸妈出去吃饭，吃饭时打游戏，吃完饭后在 Star Bark 里打游戏。真就游戏人生咯。\n有人可能要发：逆天作者，天天打游戏。但这就要谈及价值观啦。前面跑题那么多哦，终于要谈我的世界树，也就是价值观了。直接上结论，一个人想怎么活就怎么活，不论是读一辈子书，还是打一辈子游戏。自己觉得值了，那便值了。人生嘛，哪里有什么高低贵贱。人死后，他生前做了什么都与他无关了。至于他人的评论嘛，那就当是放屁。一辈子就几十年，减去睡觉吃饭，有 B 站 up 算过，9795 天，@元菜 Yilia，还能有时间在意别人的看法吗？\n就用乔布斯的话来总结吧：JUST DO IT！！！\n$MUSIC=Golden Hour$\n2. 怎么看待人生：躺着看呀 我现在就想躺平。《20 年读书，余生还房贷，死后给医院做贡献》，真实不？我想大多数人多是这样的人生吧，我假如不啃老也是。\n我高三的最后两个月，看了一些视频，彻底把我打醒了。\n一个大学生，好歹是 211 的，考了两年的研，考不上，也没工作，发视频自嘲。\n上海的一家药工厂，一个月三千，只招 985 的。\n学习是为了什么？就为了那三千块钱，或是压根找不到工作？人生是为了什么？就是为了卷一辈子？我好像一出生就走上了一条路：拼了命的考了一个好的高中，拼了命的考了一个好大学，拼了命的考研，工作后拼了命的加班是为了拼了命的还房贷。我为什么要走这条路？这条路真的非走不可吗？中国人真是“勤奋”啊，吃苦一辈子，劳累一辈子。我当然知道小镇做题家，这是他们唯一出路，但这绝不是我的唯一。\n是的，当时我觉望了，我躺了，我选择躺看人生。对了，这也不应该叫躺。我们这里，只要不加班了，只要一娱乐了，只要不上进了，就叫躺平，凭什么呀？吃苦吃的。别地的健康青年到我们这里就叫躺平了。我“躺”了两个月，即使是现在，我也是在躺平。\n《保安少走 40 年弯路，躺平少走 60 年弯路，人生何其短暂，走自己喜欢的路就行。》\n","date":"2023-09-03T20:55:25+08:00","permalink":"https://mahaoliang.tech/p/%E9%A9%AC%E7%9C%BC%E7%9C%8B%E4%B8%96%E7%95%8C/","title":"马眼看世界"},{"content":"1. 文本部分 1.1 斜体和粗体，删除线 使用 * 和 ** 表示斜体和粗体。\n示例：这是斜体，这是粗体。\n使用 ~~ 表示删除线。\n这是一段错误的文本。\n1.2 分级标题 使用 === 表示一级标题，使用 \u0026mdash; 表示二级标题。\n效果图 你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：# H1, ## H2, ### H3，#### H4。\n效果图\n1.3 常用 Emoji \u0026amp; Font-Awesome 2.0 常用布局 2.1 无序列表 使用 *，+，- 表示无序列表。\n示例：\n无序列表项 一 无序列表项 二 无序列表项 三 2.2 有序列表 使用数字和点表示有序列表。 示例：\n有序列表项 一 有序列表项 二 有序列表项 三 2.3 行内代码块 使用 代码 表示行内代码块。(就是这个``)\n2.4 插入图像 使用：\n! [描述]\n$+$\n( 图片链接地址 )\n$+$\n插入图像。\n2.5 表格支持 项目 价格 数量 计算机 $1600 5 手机 $12 12 管线 $1 234 \u0026gt; ce ce 效果图\n2.6 常用数学符号 ","date":"2023-09-03T19:58:18+08:00","permalink":"https://mahaoliang.tech/p/markdown-%E8%AF%AD%E6%B3%95/","title":"Markdown 语法"},{"content":"前言 本文借鉴了多位米游社大佬的文章，大佬名单：\n@为胡桃坐牢火本、@110000cc、@光坂镇守镇人、怎么能沉迷游戏 QAQ、@枕香半縷夢。\n好了，正片开始。\n1:2 的暴击与暴伤比最优的由来 为什么会常说暴击率：暴击伤害为 1:2 时最优？双暴很大一部分来源于圣遗物词条，而圣遗物每一个有效词条均有四个档位，如下图。\n可以发现，在同档位下，暴击与暴伤的比值正好为 1:2。这个 1:2 与最优解的比值一样，并不是巧合，解释如下。\n就拿暴击率为 3.9% 加成每词条，暴击伤害 7.8% 每词条，同一档位的为例。（取不同档位比较是无意义的）\n假设双暴有效词条数共有 x 条，暴击率有 a 条，则暴击伤害有 (x - a) 条\nx：常数，是一个已知的固定值\na：变量，由圣遗物决定，也由玩家选取决定\nx - a：变量，由圣遗物决定，也由玩家选取决定\n即此时\n$ 暴击区间=1+3.9%\\times a\\times 7.9%\\times(x-a)=1+30.42%\\times a\\times(x-a)$\n初中知识，简单的抛物线函数， 当 a 为 0.5x 时，值最大，那么此时（x - a）同样为 0.5x 即 40 个有效双暴词条，暴击率暴伤个 20 词条时（20 个有效，则各有 10 个时），伤害值最大 故在其他条件不变下，暴击词条数：暴伤词条数 = 1:1 最优 又由于每个暴伤有效词条是暴击率词条加成的 2 倍，故暴击率：暴击伤害 = 1:2 时伤害最高\n精通与双爆的分配 不同武器的被动不同，所以即使是总面板一样，伤害还是有差异的。那么按照武器分类，不同武器的最终面板与伤害的图如下： 圣遗物的选择 圣遗物选择：\n4 魔女（输出上限） 2 件套：获得 15％火元素伤害加成。 4 件套：超载、燃烧、烈绽放反应造成的伤害提升 40%，蒸发、融化反应的加成系数提高 15%。施放元素战技后的 10 秒内，2 件套的效果提高 50%，该效果最多叠加 3 次。\n4 追忆（输出相对稳定） 2 件套：攻击力提高 18%。 4 件套：施放元素战技时，如果角色的元素能量高于或等于 15 点，则会流失 15 点元素能量，使接下来的 10 秒内，普通攻击、重击、下落攻击造成的伤害提高 50%，持续期间内该效果不会再次触发。\n2 魔女 2 乐团 乐团 2 件套：元素精通提高 80 点。（寄）\n配队 胡行钟夜 yyds。\n分析：胡桃主 C，夜兰副 C 加辅助增伤加挂水，行秋减 15% 水抗加高频挂水，钟离给盾加减抗。另外，双水加 25% 生命，提高了夜兰和胡桃的输出，钟离的盾量。完美！！！\n注：夜兰带终末不仅增加了充能，还给胡桃提供了额外的精通。钟离还可以尝试一下教官套，也可以加精通。\n","date":"2023-09-01T21:16:54+08:00","permalink":"https://mahaoliang.tech/p/%E8%83%A1%E6%A1%83%E7%9A%84%E6%9C%80%E4%BC%98%E9%9D%A2%E6%9D%BF/","title":"胡桃的最优面板"},{"content":"为啥有人称我们为水军呢？我们明明还是训练的，只是不多而已。以下是我们的军训时间表。\n8.29 开始训练 7 天，10 月份再训练 7 天。\n就我亲生经历来讲，整体上不太累。我在巡时每天早上 6:40 起床，7:30 在食堂吃完早餐，7:50 集合，8:00 开训，练到 9 点多开始坐着唱军歌（休息），10:20 结束早上训练。下午 1:40 集合，听讲座，又是睡觉时间，听到 4:30 结束下午的训练。要说累，就是晚上训练很累，6:00 集合，到二期校园的体育场练习。走过去 20 分钟回来 20 分钟，期间要训练两个多小时，9 点多回到一期校园，结束训练。\n训练时手机要上交，训练完了就会拿回来。训练过程中的休息时间的长短要看教官。我的教官就挺好的，休息训练五五开\n重点来了，军训累不累还要看老天爷的心情。停训的时间是不会补回来的！！！\n最后，在提一点注意要点。\n军训的穿的军鞋质量很烂，站久了脚会很疼，而且鞋底还会掉色，白袜子会被染黑的，我舍友就是例子。所以，为了您的脚和袜子，一定要买一双鞋垫，塞进去垫着。\n","date":"2023-09-01T19:23:19+08:00","permalink":"https://mahaoliang.tech/p/uic-%E7%9A%84%E5%86%9B%E8%AE%AD%E6%97%A5%E8%AE%B0/","title":"UIC 的军训日记"},{"content":"生成新的文章 进入到本机网站目录\n1 cd documents/works/mahaoliang/mahaoliang.stack.tech 在保存本机网站的目录下运行下面的命令，生成一篇文章\n1 hugo new post/kubernetes-overview.md 编辑文章 使用 Typora 打开新建的文章，首先编辑文章的元信息：\n1 2 3 4 5 title: \u0026#34;Kubernetes工作原理概述\u0026#34; date: 2022-07-22T17:30:11+08:00 draft: false tags: [docker,linux,kubernetes] categories: [tech] 然后编辑文章内容，图片使用 picGo 上传到图床。\n将文章发布到 GitHub 在保存本机网站的目录下运行下面的命令，将文章发布到 GitHub\n1 2 3 git add . git commit -m \u0026#34;kubernetes\u0026#34; git push 网站内容更新 登录到腾讯云主机，\n1 ssh guangzhou-tencent 进入 ~/works/mahaoliang.stack 目录，执行命令：\n1 git pull 完成\n","date":"2023-08-31T20:54:03+08:00","permalink":"https://mahaoliang.tech/p/%E6%96%87%E7%AB%A0%E5%8F%91%E8%A1%A8/","title":"文章发表"},{"content":"雅思学习｜心得 ∆口语 口语对于我来说是最难的部分，不仅仅有社恐的因素，还有 oral speaking 的语速问题（over 120 words per minute is standard）。\n特别要注意的是口音并不太重要，重要的是 例子！！栗子！！真实例子！！ 不管是 part 1，part 2，还是 part 3，都需要例子，只不过每个 part 的例子各有区别罢了。区别后面讲。 不能有太多的停顿，一个问题最多两个停顿，多了就有可能扣分，再多些考官就会 cut you out，然后你的心态就可能会崩，导致后面答题的状态，引发蝴蝶效应。 注意时间限制，part one 和 part three 一个问题回答一分钟左右，没有准备时间！！！part two 有一分钟的准备时间，给一张纸让考生写提示词，讲述时可以看。 Part 1 在 part 1 时，举例子只用举自己的轻身例子，并用第一人称讲述。讲述时，时态讲错了不用管，因为不重要，重要的是要讲述具体细节\n例如，说出去吃饭时要说清楚和谁去（who），为什么去（why），什么时候去的（when），去哪里吃（where），吃的什么类型的餐厅的什么菜 (what)，心情如何（how），即6W 要素。\neg. I usually hang out with my best friend, Tom, to have a big meal on weekends in a shopping centre like the Coastal City in Nan Shan district in Shenzhen because the food in school\u0026rsquo;s canteen is tasteless. And we always go to the Green Tea restaurant there, a famous chinese restaurant, for having some crispy chicken, spicy tofu, or the boiled Fish with Sichuan pickles. That really makes me a happy mood to face the disgusting food next week in school.\n在上面的例子中，我每提出一个概念都给出了解释或是具体的事物。例如，friend 是 Tom，a shopping centre 是深圳南山区的海岸城 the Coastal City，the Green Tea restaurant 是一家中餐厅。以上就是我所说的具体细节，就是得分要点。没有细节口语就不可能上 6 分，只有 5 分。\nPart 2 在 part 2 时，也要举亲身经历，题目怎么问就怎么答，讲出具体细节就可以了。准备时，最好四十秒写提示词，二十秒再在脑中过一遍，以免出现太多停顿。\n例如题目：Describe a daily routine that you enjoy\nYou should say, what you do, when it became your daily routine, whether you will change it in the future, and explain why you enjoy it\neg.\nThe daily routine I am going to tell you about is that I jog at around 6 pm nearly every afternoon. At that time, the sun has already started sinking, but the darkness has not fallen, creating a mild temperature. Right next to my community is a huge park stretching over 2 kilometers, which is a perfect place to run around. Sometimes, I would also go to the stadium several blocks away. It has a standard 400-meter track, enabling me to precisely calculate the distance and speed.\nI developed this habit several months ago when I accidentally caught Xiaoming doing some warm-up activities at the side of the street on my way back from the library. I pulled over my electric bicycle and asked what he was doing. He said he was going to start his daily jogging and invited me to jog together. I thought, why not. But what I did not expect was that I overestimated my stamina. After one kilometer, I felt I could not breathe and had to give up. But since then, I have jogged with him almost every day.\nI do not think I will change this daily routine in the near future because it has substantially improved my health. Before I jogged, I suffered from sub-health resulting from my sedentary lifestyle. I felt tightness in my chest now and then, my back and waist ached, and I could not help panting after climbing only two floors. But now, these problems rarely surface.\nApart from the health benefits I have mentioned, I enjoy jogging because it can soothe my tense nerves. You know, it helps me concentrate on my breaths and steps and thus temporarily escape from all the troubles.\n在上面的回答中，加粗的字是要写在纸上的，其他部分就只能自由发挥了\nPart 3 在 part 3 时，回答的方式和 part 1 差不多，只是第一人称要换成第三人称，如 the people，they，them 和 their。讲述时按照OREO的方法就可以了，讲述时间不能超过 1 分钟，40 秒就足够了。举例的时候，只用举一个就可以了，越详细越好。\n例如：Q do people\u0026rsquo;s routines differ on weekdays and weekends?\neg.\nThe routines on weekdays are regular but routines on weekends are not. (opinion) (reason) For example, people have to go to school or go to the workplace at 7 am every weekday and have lunch at 12 o’clock, and they had to stay at school or work place until at about 6 PM. But on the weekends, people can get up late at around 11am if they want, having a big meal in the restaurant like the green tea restaurant for the crispy chicken and spicy tofu. And they can go home at any time they want.(example) so the routines on weekends are flexible but on weekdays are stricted.(opinion) 如何讲好例子 背景（一句话）\n4、5 个 actions ————\u0026gt;good example\n2、3 个 actions————\u0026gt;small example\n结果，the end\n例如：Describe the word \u0026ldquo;patience\u0026rdquo; .\neg.\nIf a naughty kid is making noise, laughing and shouting, in a public place like the library named the Book City in Nan Shan district in Shenzhen and his parents are not there （background）, I will not get mad at him or punch on his face. I will first grab his hands to stop him from running around the whole place, and tell him to be quiet. （actions） Then, I will send him to his parents to tell about his bad behavour, to make sure that he will not make noise in the public any more. （the end） 注：加粗为 actions ∆阅读 题型 顺序题：\n填空题（sentence completion 和 short answer question） 判断题（T/F/NG 和 T/N/NG） 选择题（multiple choice） 乱序题：\n人物匹配题（matching features） 中心句匹配题（matching headings） 信息匹配题（matching information） 注意 做信息匹配题时，要先读题，思考题目中的关键词会替换成什么。 人物匹配题和信息匹配题出现 NB 时，代表有一个人会被选两次，或有一段会选两个信息。 ∆写作 类型 小作文\n流程图 数据图 大作文\n内容 小作文\n信息转述（Introduction） 总述（overview） 特点一（feature one） 特点二（feature two） 大作文\n信息转述（introduction） 一方面（1st side） 另一方面（2nd side） 总结（conclusion） ∆听力 题型 填空题 选择题（单/多） 地图题 注意 同义替换，一般与答案一起出现 ","date":"2023-08-29T21:59:36+08:00","permalink":"https://mahaoliang.tech/p/ielts-learning/","title":"IELTS Learning"},{"content":"SDKMAN！是用于管理多个软件开发工具包的并行版本的工具。\n可安装的软件列表\n列出当前可安装的软件列表 1 sdk list 列出当前可安装的 Java 版本列表 1 sdk list java 安装指定的版本 1 sdk install java 17.0.7-tem 查看当前使用的版本 1 2 sdk current sdk current java 设置缺失使用的版本 1 sdk default java 17.0.7-tem 设置当前 shell session 使用的版本 1 sdk use java 8.0.332-tem 更新软件仓库 1 sdk update sdk 软件本身的更新 1 sdk selfupdate ","date":"2023-06-24T18:08:17+08:00","permalink":"https://mahaoliang.tech/p/sdkman-%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"Sdkman 的使用"},{"content":"1Password的最大优势是跨平台，不管是苹果系的 iOS，macOS，还是 Google 的 Android，微软的 Windows，以及 Linux，都能完美支持。让你在 macOS 上使用 Safari，在 Windows 上使用 Edge，Android 上使用 Chrome 时，都能无缝得到密码管理的支持。这是苹果自带的密码管理所不能满足的。\n如何使用好 1Password，官方文档Get started with 1Password是最好的学习素材，快速浏览一遍，基本会使用完全没有问题。\n这篇文档我只重点介绍在 macOS 和 iOS 上使用 1Password 时的一些注意事项。\n安装 macOS 和 iOS 上的 Safari，都需要打开1Password 插件。\nmacOS 的 Safari 插件直接在 App Store 安装。\niOS 上插件的安装请参考：Get to know 1Password for Safari on your iPhone or iPad\nOpen Safari to any website and tap in the address bar.\nIf you\u0026rsquo;re using an iPad, tap in the address bar.\nTap Manage Extensions and turn on 1Password, then tap Done.\n关掉内置密码管理 由于 Safari 自带了密码管理，同时打开会和 1Password 有冲突，因此需要关闭内置的密码管理。\n具体操作参考官方文档Turn off the built-in password manager in your browser。\nmacOS 上 Safari 的设置 To stop Safari from asking to save your passwords:\nClick the Safari menu and choose Preferences. Click the AutoFill icon. Turn off all the AutoFill web forms settings: “Using info from my contacts”, “User names and passwords”, “Credit cards”, and “Other forms”. iOS 上 Safari 的设置 To stop Safari from asking to save your passwords:\nOpen Settings, then tap Passwords \u0026amp; Accounts. Tap AutoFill Passwords. Turn off iCloud Keychain. iOS 上 App 的支持 iOS 上 app 使用 1Password 的体验和 Safari 是一致的，只要 app 使用 iOS 系统标准键盘，在需要输入用户名和密码的地方，会自动出现钥匙图标，点击钥匙，会呼出 1Password 进行自动填充。\n然而很多国产银行类 app，基本都不使用 iOS 内置键盘，所以没法呼出 1Password。这时候只能自己进入 1Password 进行拷贝密码或创建密码的操作。\nUniversal Autofill Universal Autofill 是 1Password 8的一个重大升级功能。Universal Autofill 实现了真正的「全局填充」。你只要记住一个快捷键 Command + \\ ，就可以在浏览器、应用程序、终端和系统提示等任何地方，让 1Password 帮你自动完成密码填充。\n两步认证 对于已经支持 1Password 两步认证 的网站，都已经迁移到了 1Password。\n如果 1Password 本身开启了两步认证，它就需要一个第三方的 Authenticator，因为它不可能自己保存自己的 one-time password，官方文档已经说明。我选择了微软的Authenticator。\n微软的 Authenticator 可以备份和恢复，在换手机时非常方便。另外使用 Authenticator 登录微软账号时体验很好，不需要输入密码，只用在手机上确认即可，体验类似扫码登录，但又不用扫码:)\n管理 SSH Keys 1Password 可以保存你的 SSH keys，并作为 SSH agent ，无缝整合 SSH 和 Git 工作流。同时，在 GitHub 等平台需要填写公钥的地方，自动帮你拷贝填充公钥。\n生成或导入 SSH keys 我们可以使用 ssh-keygen 命令自己生成 SSH key，也可以在 1Password 中创建 SSH key 项目时自动生成。 开启 1Password SSH Agent 1Password SSH Agent 使用你保存在 1Password 中的 SSH Key，与你的 Git 和 SSH 工作流程无缝集成。它可以验证你的 Git 和 SSH 客户端，而这些客户端永远无法读取你的私钥。\n首先要打开 1Password SSH Agent，让它在后台运行，为你的 SSH 客户端处理认证。打开 1Password \u0026gt; 偏好设置 \u0026gt; 开发者，勾选“使用 SSH agent”和“授权连接时显示密钥名称”。 为了确保 SSH Agent 在后台持续运行，需要在 1Password \u0026gt; 偏好设置 \u0026gt; 通用 中，勾选“在菜单栏中保留 1Password”。\n配置 SSH 客户端 为了让 SSH 客户端能使用 1Password SSH agent，需要将 IdentityAgent 配置添加到 ~/.ssh/config文件中：\n1 2 Host * IdentityAgent \u0026#34;~/Library/Group Containers/2BUA8C4S2C.com.1password/t/agent.sock\u0026#34; 你也可以在 Shell 中设置 SSH_AUTH_SOCK 环境变量：\n1 export SSH_AUTH_SOCK=~/Library/Group\\ Containers/2BUA8C4S2C.com.1password/t/agent.sock 如果觉得 agent 路径过于复杂，可以先创建一个符号链接：\n1 mkdir -p ~/.1password \u0026amp;\u0026amp; ln -s ~/Library/Group\\ Containers/2BUA8C4S2C.com.1password/t/agent.sock ~/.1password/agent.sock 这样就可以在设置环境变量时直接引用符号链接：\n1 export SSH_AUTH_SOCK=${HOME}/.1password/agent.sock 现在 SSH 客户端就可以在登录远程主机时使用 1Password SSH agent。\n可以使用下面的命令查看，1Password SSH agent 帮我们管理的 SSH Keys：\n1 ssh-add -L 发布 SSH 公钥 我们需要使用某种方式，将 SSH 公钥发布到远程服务器，以便对方能利用公钥验证你的身份。\n一种方式是把公钥上传到服务提供者的网站，将公钥和你的账号绑定。例如你可以在GitHub SSH key settings页面上传公钥。腾讯云的管理控制台也可以上传你的公钥，然后将公钥和你购买的服务器绑定。在页面填写公钥时，1Password 会像填充密码一样进行自动填充。\n另一种方式就是使用 ssh-copy-id 命令，直接将公钥拷贝到远程服务器。\n不管使用哪种方式，一定要记住你发布的是公钥，千万不能不小心泄漏了私钥。\n管理 Github Signing Key Github 开始支持使用 SSH Key 来签名提交，也就是说，我们可以用 1Password 管理的 SSH key 来签名 git commit。\n设置过程可以参考Sign your Git commits with 1Password，主要包含两个步骤：\n在 GitHub 上生成 Signing Key。访问https://github.com/settings/keys ，选择“New SSH Key”，选择 key 的类型为“Signing Key”，然后填入 1Password 管理的 SSH 公钥。 配置本地的 .gitconfig。在 1Password 中，选择 SSH Key，并在上面显示的横幅中选择 \u0026ldquo;配置 \u0026ldquo;选项： 按照提示，配置你的 .gitconfig文件。这些设置选择了你的 SSH key，并在 git commit 的时候使用 SSH Key 签名。\n“Sign in with” anything 1Password 将记住用户使用的第三方登录服务（如 sign in with Google）。看官方消息，这个功能很快会上线。\n","date":"2022-09-29T22:06:18+08:00","permalink":"https://mahaoliang.tech/p/1password-%E5%9C%A8-macos-%E5%92%8C-ios-%E4%B8%8A%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"1Password 在 macOS 和 iOS 上的使用技巧"},{"content":"基本设置 打开终端的偏好设置，点击描述文件tab，将 Pro 设置为默认描述文件。\n然后对 Pro 进行配置。\nTab 页 设置 文本 勾选“平滑文本”。可自定义背景透明度。 窗口 窗口大小：行 120 列 30 窗口 选择 将行数限制为：10000 shell 当 shell 退出时，选择当 shell 完全退出后关闭 键盘 勾选 将 option 键当 Meta 键 高级 确认终端为 xterm-256 color 安装Xcode Command Line Tools Xcode Command Line Tools 包含了clang编译器，git客户端等命令行常用的工具。使用下面的命令安装：\n1 xcode-select --install 安装Oh My Zsh 参照 Oh My ZSH! 的官方文档进行安装。\n1 2 3 4 5 #确认zsh版本 zsh --version #执行安装 sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 如出现连接问题，请在终端设置科学上网。\n1 export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890 安装和配置 Powerlevel10k powerlevel10k 是一个 Zsh 的主题，具体很强的灵活性，并且非常美观。\n首先安装 Powerlevel10k 所推荐的字体 Meslo Nerd Font，可以在命令行终端显示一些特殊符号。下载并安装下列字体：\nMesloLGS NF Regular.ttf MesloLGS NF Bold.ttf MesloLGS NF Italic.ttf MesloLGS NF Bold Italic.ttf 然后更改终端的字体，在终端的偏好设置的的描述文件中，选择我们使用的 Pro，设置字体为MesloLGS NF，字体大小为 14。\n由于我们使用的是 Oh My Zsh，可以把 Powerlevel10k 作为一个主题，安装到 Oh My Zsh 中：\n1 git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 如果遇到网络问题，可以参考上面，设置终端科学上网代理。\n编辑 Oh My Zsh 的配置文件 ~/.zshrc，设置主题为 Powerlevel10k\n1 ZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34; 重新开启终端，按照提示进行 Powerlevel10k 的样式配置，完成后，我们漂亮的命令行终端配置就大功告成了。\n如果你在使用VSCode，需要在配置文件settings.json中设置下面两个配置，你就可以让VSCode的终端同样适配 Powerlevel10k。\n1 2 \u0026#34;terminal.integrated.fontSize\u0026#34;: 14, \u0026#34;terminal.integrated.fontFamily\u0026#34;: \u0026#34;MesloLGS NF\u0026#34; 安装 zsh-autosuggestions 插件 Oh My Zsh 在安装完成后，已经自动配置了 git 插件。为了在命令行终端更快捷的工作，还可以为 Oh My Zsh 安装zsh-autosuggestions 插件。\nzsh-autosuggestions 提供类似于Fish shell 自动建议功能，它会根据历史记录，在你键入命令的时候，提供非侵入式的自动建议。\n安装zsh-autosuggestions 的命令：\n1 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 在 ~/.zshrc 中配置插件：\n1 plugins=(git zsh-autosuggestions) 在键入命令时，会有灰色的提示信息，按 → 或 ctrl-f 自动完成。是不是非常方便，用过后就完全离不开了。\n命令别名配置 使用命令行操作非常快速便捷，但有时候你不知道命令具体干了什么，例如我输入的 rm *到底删除了哪些文件。\n其实这些命令都有参数，详细的输出该命令影响的文件。但每次都输入这些参数实在太麻烦，我们可以在 Zsh 的配置文件 ~/.zshrc 中为这些命令设置别名：\n1 2 3 4 5 alias mkdir=\u0026#39;mkdir -v\u0026#39; alias mv=\u0026#39;mv -v\u0026#39; alias cp=\u0026#39;cp -v\u0026#39; alias rm=\u0026#39;rm -v\u0026#39; alias ln=\u0026#39;ln -v\u0026#39; ","date":"2022-07-23T15:26:12+08:00","permalink":"https://mahaoliang.tech/p/%E6%89%93%E9%80%A0%E4%B8%80%E4%B8%AA%E6%BC%82%E4%BA%AE%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BB%88%E7%AB%AF/","title":"打造一个漂亮的命令行终端"},{"content":"拿到一台新的 MacBook，总是要经过一些设置才能让它变得顺手好用。这些配置也许对你也有启发和帮助。\n触控板设置 单指轻点代表单击。拿到 MacBook 第一个要设置的，对它轻柔一些，单击毫不费力 四指左右轻扫，桌面间切换 四指向上，进入调度中心。“调度中心”提供了一个鸟瞰图，平铺了所有应用的窗口、桌面空间，可以轻松地在它们之间切换。点击右上角“+”号可以创建新桌面。 四指向下，App Expose，查看正在使用的 App 的所有窗口。 设置三指拖移：苹果菜单  \u0026gt; “系统偏好设置” \u0026gt; “辅助功能” \u0026gt; “指针控制” \u0026gt; “触控板选项” \u0026gt; “启用拖移”，然后从菜单中选取“三指拖移”。 词典配置 在触控板设置中，勾选“三指轻点”触发查询与数据检查器。\n在词典应用的偏好设置中，除了缺省选择的词典，建议增加勾选一个英英词典。用英语解释英语单词，就想我们查汉语词典一样，是一种更地道的学习英语方式。\n在任何应用中，都可以通过“三指轻点”，触发词典。因为是系统原生支持，体验丝滑顺畅。\n原生词典方便好用，但是没有单词本功能。网上找到一种利用“自动操作”生成单词本的方法，可以尝试。\n系统偏好设置 滚动条设置\n始终显示滚动条 跳至点按的位置 触发脚设置\n右下角显示桌面 左上角屏幕保护。在安全和隐私中设置：进入屏幕保护后立即要求输入密码。这样既是屏保又可以锁屏 移除 Dock 上大部分可以用 Spotlight 唤出的应用。\n设置 Dock 自动隐藏，扩大桌面可用区域。\nF1~F12 保持缺省设置，作为特殊功能键。如果需要使用 F1~F12 的标准功能，需要配合fn\n关闭英文自动补全。系统偏好设置 \u0026gt; 键盘 \u0026gt; 文本 \u0026gt; 取消自动纠正拼写。\n控制中心设置 为了节省菜单栏的空间，可以让不用的控制项只在控制中心显示，不在占用菜单栏，如蓝牙，隔空投送等。\nSpotlight 可以用快捷键呼出，不用在菜单栏显示。\n时间可以用 24 小时制，缩短占用的菜单栏。\n按住 Cmd 键，可以用指针拖动菜单栏图标，按你喜欢的顺序排列。\nFinder 设置 Finder 中的“个人收藏”可以偏好设置中进行定制，可以把常用的文件夹拖到个人收藏 Finder 的四种显示模式，个人喜欢分栏模式 可自定义 Finder 工具栏 显示路径栏 网络设置 为系统设置 DNS，选择可靠 DNS 服务：\n阿里云 DNS 223.5.5.5 和 223.5.5.5。 腾讯云 DNS 119.29.29.29 ","date":"2022-07-23T14:51:18+08:00","permalink":"https://mahaoliang.tech/p/macos-%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%BB%BA%E8%AE%AE%E8%AE%BE%E7%BD%AE/","title":"macOS 的系统建议设置"}]